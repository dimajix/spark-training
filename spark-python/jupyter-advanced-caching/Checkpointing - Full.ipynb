{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpointing DataFrames\n",
    "\n",
    "Sometimes execution plans can get pretty long and Spark might run into trouble. Common scenarios are iterative algorithms like ML or graph algorithms, which contain a big outer loop and iteratively transform a DataFrame over and over again. This would result in a really huge execution plan.\n",
    "\n",
    "In these cases you could use `cache()` or `persist()` in order to improve performance (otherwise all steps of the loop would be executed again from the very beginning leading to a runtime of O(n^2)). But this will not cut off the lineage.\n",
    "\n",
    "Checkpointing is the right solution for these cases. It will persist the data of a DataFrame in a reliable distributed storage (most commonly HDFS) and cut off the lineage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load Data\n",
    "\n",
    "We will load the weather data again for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "storageLocation = \"s3://dimajix-training/data/weather\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "raw_weather = spark.read.text(storageLocation + \"/2003\").withColumn(\"year\", lit(2003))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Measurements\n",
    "\n",
    "Measurements were stored in a proprietary text based format, with some values at fixed positions. We need to extract these values with a simple `SELECT` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>usaf</th>\n",
       "      <th>wban</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>report_type</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_direction_qual</th>\n",
       "      <th>wind_observation</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_speed_qual</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>air_temperature_qual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0000</td>\n",
       "      <td>SY-MT</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0017</td>\n",
       "      <td>FM-16</td>\n",
       "      <td>020</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0053</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0100</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0153</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0200</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0253</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0300</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0353</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>020</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0400</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    usaf   wban      date  time report_type wind_direction  \\\n",
       "0  2003  703160  25624  20030101  0000       SY-MT            010   \n",
       "1  2003  703160  25624  20030101  0017       FM-16            020   \n",
       "2  2003  703160  25624  20030101  0053       FM-15            010   \n",
       "3  2003  703160  25624  20030101  0100       NSRDB            999   \n",
       "4  2003  703160  25624  20030101  0153       FM-15            010   \n",
       "5  2003  703160  25624  20030101  0200       NSRDB            999   \n",
       "6  2003  703160  25624  20030101  0253       FM-15            010   \n",
       "7  2003  703160  25624  20030101  0300       NSRDB            999   \n",
       "8  2003  703160  25624  20030101  0353       FM-15            020   \n",
       "9  2003  703160  25624  20030101  0400       NSRDB            999   \n",
       "\n",
       "  wind_direction_qual wind_observation  wind_speed wind_speed_qual  \\\n",
       "0                   5                N         5.2               5   \n",
       "1                   1                N         4.6               1   \n",
       "2                   5                N         5.2               5   \n",
       "3                   9                9       999.9               9   \n",
       "4                   5                N         6.2               5   \n",
       "5                   9                9       999.9               9   \n",
       "6                   5                N         7.2               5   \n",
       "7                   9                9       999.9               9   \n",
       "8                   5                N         6.2               5   \n",
       "9                   9                9       999.9               9   \n",
       "\n",
       "   air_temperature air_temperature_qual  \n",
       "0             -0.6                    5  \n",
       "1             -2.0                    1  \n",
       "2             -2.8                    5  \n",
       "3            999.9                    9  \n",
       "4             -2.2                    5  \n",
       "5            999.9                    9  \n",
       "6             -3.3                    5  \n",
       "7            999.9                    9  \n",
       "8             -1.1                    5  \n",
       "9            999.9                    9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = raw_weather.select(\n",
    "    col(\"year\"),\n",
    "    substring(col(\"value\"),5,6).alias(\"usaf\"),\n",
    "    substring(col(\"value\"),11,5).alias(\"wban\"),\n",
    "    substring(col(\"value\"),16,8).alias(\"date\"),\n",
    "    substring(col(\"value\"),24,4).alias(\"time\"),\n",
    "    substring(col(\"value\"),42,5).alias(\"report_type\"),\n",
    "    substring(col(\"value\"),61,3).alias(\"wind_direction\"),\n",
    "    substring(col(\"value\"),64,1).alias(\"wind_direction_qual\"),\n",
    "    substring(col(\"value\"),65,1).alias(\"wind_observation\"),\n",
    "    (substring(col(\"value\"),66,4).cast(\"float\") / lit(10.0)).alias(\"wind_speed\"),\n",
    "    substring(col(\"value\"),70,1).alias(\"wind_speed_qual\"),\n",
    "    (substring(col(\"value\"),88,5).cast(\"float\") / lit(10.0)).alias(\"air_temperature\"),\n",
    "    substring(col(\"value\"),93,1).alias(\"air_temperature_qual\")\n",
    ")\n",
    "    \n",
    "weather.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load Station Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAF</th>\n",
       "      <th>WBAN</th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>CTRY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ELEV(M)</th>\n",
       "      <th>BEGIN</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007005</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07005</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20120127</td>\n",
       "      <td>20120127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007011</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07011</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20111025</td>\n",
       "      <td>20121129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007018</td>\n",
       "      <td>99999</td>\n",
       "      <td>WXPOD 7018</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>+00.000</td>\n",
       "      <td>+000.000</td>\n",
       "      <td>+7018.0</td>\n",
       "      <td>20110309</td>\n",
       "      <td>20130730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007025</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07025</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20120127</td>\n",
       "      <td>20120127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007026</td>\n",
       "      <td>99999</td>\n",
       "      <td>WXPOD 7026</td>\n",
       "      <td>AF</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>+00.000</td>\n",
       "      <td>+000.000</td>\n",
       "      <td>+7026.0</td>\n",
       "      <td>20120713</td>\n",
       "      <td>20141120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>007034</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07034</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20121024</td>\n",
       "      <td>20121106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>007037</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07037</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20111202</td>\n",
       "      <td>20121125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>007044</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07044</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20120127</td>\n",
       "      <td>20120127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>007047</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07047</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20120613</td>\n",
       "      <td>20120717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>007052</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07052</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20121129</td>\n",
       "      <td>20121130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     USAF   WBAN STATION NAME  CTRY STATE  ICAO      LAT       LON  ELEV(M)  \\\n",
       "0  007005  99999   CWOS 07005  None  None  None     None      None     None   \n",
       "1  007011  99999   CWOS 07011  None  None  None     None      None     None   \n",
       "2  007018  99999   WXPOD 7018  None  None  None  +00.000  +000.000  +7018.0   \n",
       "3  007025  99999   CWOS 07025  None  None  None     None      None     None   \n",
       "4  007026  99999   WXPOD 7026    AF  None  None  +00.000  +000.000  +7026.0   \n",
       "5  007034  99999   CWOS 07034  None  None  None     None      None     None   \n",
       "6  007037  99999   CWOS 07037  None  None  None     None      None     None   \n",
       "7  007044  99999   CWOS 07044  None  None  None     None      None     None   \n",
       "8  007047  99999   CWOS 07047  None  None  None     None      None     None   \n",
       "9  007052  99999   CWOS 07052  None  None  None     None      None     None   \n",
       "\n",
       "      BEGIN       END  \n",
       "0  20120127  20120127  \n",
       "1  20111025  20121129  \n",
       "2  20110309  20130730  \n",
       "3  20120127  20120127  \n",
       "4  20120713  20141120  \n",
       "5  20121024  20121106  \n",
       "6  20111202  20121125  \n",
       "7  20120127  20120127  \n",
       "8  20120613  20120717  \n",
       "9  20121129  20121130  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(storageLocation + \"/isd-history\")\n",
    "\n",
    "# Display first 10 records    \n",
    "stations.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Join Data\n",
    "\n",
    "Now we perform the join between the station master data and the measurements, as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_weather = weather.join(stations, (weather[\"usaf\"] == stations[\"usaf\"]) & (weather[\"wban\"] == stations[\"wban\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Truncating Execution Plans\n",
    "\n",
    "Now we want to understand the effect of checkpointing. First we will use the traditional aggregation and print the execution plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Traditional Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate [ctry#45, year#2], [ctry#45, year#2, min(CASE WHEN (air_temperature_qual#16 = 1) THEN air_temperature#15 END) AS min_temp#173, max(CASE WHEN (air_temperature_qual#16 = 1) THEN air_temperature#15 END) AS max_temp#175]\n",
      "+- AnalysisBarrier\n",
      "      +- Join Inner, ((usaf#5 = usaf#42) && (wban#6 = wban#43))\n",
      "         :- Project [year#2, substring(value#0, 5, 6) AS usaf#5, substring(value#0, 11, 5) AS wban#6, substring(value#0, 16, 8) AS date#7, substring(value#0, 24, 4) AS time#8, substring(value#0, 42, 5) AS report_type#9, substring(value#0, 61, 3) AS wind_direction#10, substring(value#0, 64, 1) AS wind_direction_qual#11, substring(value#0, 65, 1) AS wind_observation#12, (cast(cast(substring(value#0, 66, 4) as float) as double) / cast(10.0 as double)) AS wind_speed#13, substring(value#0, 70, 1) AS wind_speed_qual#14, (cast(cast(substring(value#0, 88, 5) as float) as double) / cast(10.0 as double)) AS air_temperature#15, substring(value#0, 93, 1) AS air_temperature_qual#16]\n",
      "         :  +- Project [value#0, 2003 AS year#2]\n",
      "         :     +- Relation[value#0] text\n",
      "         +- Relation[USAF#42,WBAN#43,STATION NAME#44,CTRY#45,STATE#46,ICAO#47,LAT#48,LON#49,ELEV(M)#50,BEGIN#51,END#52] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "ctry: string, year: int, min_temp: double, max_temp: double\n",
      "Aggregate [ctry#45, year#2], [ctry#45, year#2, min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS min_temp#173, max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS max_temp#175]\n",
      "+- Join Inner, ((usaf#5 = usaf#42) && (wban#6 = wban#43))\n",
      "   :- Project [year#2, substring(value#0, 5, 6) AS usaf#5, substring(value#0, 11, 5) AS wban#6, substring(value#0, 16, 8) AS date#7, substring(value#0, 24, 4) AS time#8, substring(value#0, 42, 5) AS report_type#9, substring(value#0, 61, 3) AS wind_direction#10, substring(value#0, 64, 1) AS wind_direction_qual#11, substring(value#0, 65, 1) AS wind_observation#12, (cast(cast(substring(value#0, 66, 4) as float) as double) / cast(10.0 as double)) AS wind_speed#13, substring(value#0, 70, 1) AS wind_speed_qual#14, (cast(cast(substring(value#0, 88, 5) as float) as double) / cast(10.0 as double)) AS air_temperature#15, substring(value#0, 93, 1) AS air_temperature_qual#16]\n",
      "   :  +- Project [value#0, 2003 AS year#2]\n",
      "   :     +- Relation[value#0] text\n",
      "   +- Relation[USAF#42,WBAN#43,STATION NAME#44,CTRY#45,STATE#46,ICAO#47,LAT#48,LON#49,ELEV(M)#50,BEGIN#51,END#52] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [ctry#45, 2003], [ctry#45, 2003 AS year#2, min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS min_temp#173, max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS max_temp#175]\n",
      "+- Project [air_temperature#15, air_temperature_qual#16, CTRY#45]\n",
      "   +- Join Inner, ((usaf#5 = usaf#42) && (wban#6 = wban#43))\n",
      "      :- Project [substring(value#0, 5, 6) AS usaf#5, substring(value#0, 11, 5) AS wban#6, (cast(cast(substring(value#0, 88, 5) as float) as double) / 10.0) AS air_temperature#15, substring(value#0, 93, 1) AS air_temperature_qual#16]\n",
      "      :  +- Filter (isnotnull(substring(value#0, 11, 5)) && isnotnull(substring(value#0, 5, 6)))\n",
      "      :     +- Relation[value#0] text\n",
      "      +- Project [USAF#42, WBAN#43, CTRY#45]\n",
      "         +- Filter (isnotnull(usaf#42) && isnotnull(wban#43))\n",
      "            +- Relation[USAF#42,WBAN#43,STATION NAME#44,CTRY#45,STATE#46,ICAO#47,LAT#48,LON#49,ELEV(M)#50,BEGIN#51,END#52] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(3) HashAggregate(keys=[ctry#45, 2003#180], functions=[min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END), max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END)], output=[ctry#45, year#2, min_temp#173, max_temp#175])\n",
      "+- Exchange hashpartitioning(ctry#45, 2003#180, 200)\n",
      "   +- *(2) HashAggregate(keys=[ctry#45, 2003 AS 2003#180], functions=[partial_min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END), partial_max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END)], output=[ctry#45, 2003#180, min#183, max#184])\n",
      "      +- *(2) Project [air_temperature#15, air_temperature_qual#16, CTRY#45]\n",
      "         +- *(2) BroadcastHashJoin [usaf#5, wban#6], [usaf#42, wban#43], Inner, BuildRight\n",
      "            :- *(2) Project [substring(value#0, 5, 6) AS usaf#5, substring(value#0, 11, 5) AS wban#6, (cast(cast(substring(value#0, 88, 5) as float) as double) / 10.0) AS air_temperature#15, substring(value#0, 93, 1) AS air_temperature_qual#16]\n",
      "            :  +- *(2) Filter (isnotnull(substring(value#0, 11, 5)) && isnotnull(substring(value#0, 5, 6)))\n",
      "            :     +- *(2) FileScan text [value#0] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true], input[1, string, true]))\n",
      "               +- *(1) Project [USAF#42, WBAN#43, CTRY#45]\n",
      "                  +- *(1) Filter (isnotnull(usaf#42) && isnotnull(wban#43))\n",
      "                     +- *(1) FileScan csv [USAF#42,WBAN#43,CTRY#45] Batched: false, Format: CSV, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/isd-history], PartitionFilters: [], PushedFilters: [IsNotNull(USAF), IsNotNull(WBAN)], ReadSchema: struct<USAF:string,WBAN:string,CTRY:string>\n"
     ]
    }
   ],
   "source": [
    "result = joined_weather.groupBy(joined_weather[\"ctry\"], joined_weather[\"year\"]).agg(\n",
    "        min(when(joined_weather.air_temperature_qual == lit(1), joined_weather.air_temperature)).alias('min_temp'),\n",
    "        max(when(joined_weather.air_temperature_qual == lit(1), joined_weather.air_temperature)).alias('max_temp')\n",
    ")\n",
    "\n",
    "result.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Reliable Checkpointing\n",
    "\n",
    "Now we first checkpoint the joined weather data set and then perform the aggregation on the checkpointed DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Checkpoint directory\n",
    "\n",
    "First we need to specify a checkpoint directory on a reliable shared file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir(\"/tmp/checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create checkpoint\n",
    "\n",
    "Now we can create a checkpoint for the joined weather. Note that this takes some time, as checkpointing is not a lazy operation, it will be executed immediately. This is also conceptionally neccessary, because one aspect of checkpointing is that the whole lineage gets cut off. So there is no way around executing the computation for materializing the DataFrame inside the checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_weather = joined_weather.checkpoint(eager=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - hadoop hadoop          0 2018-10-28 07:37 /tmp/checkpoints/1e08381c-ddda-4d02-876b-07ba3427c9f8\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -ls /tmp/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect execution plan\n",
    "\n",
    "Let us have a look at the execution plan of the checkpointed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "AnalysisBarrier\n",
      "   +- LogicalRDD [year#2, usaf#5, wban#6, date#7, time#8, report_type#9, wind_direction#10, wind_direction_qual#11, wind_observation#12, wind_speed#13, wind_speed_qual#14, air_temperature#15, air_temperature_qual#16, USAF#42, WBAN#43, STATION NAME#44, CTRY#45, STATE#46, ICAO#47, LAT#48, LON#49, ELEV(M)#50, BEGIN#51, END#52], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "year: int, usaf: string, wban: string, date: string, time: string, report_type: string, wind_direction: string, wind_direction_qual: string, wind_observation: string, wind_speed: double, wind_speed_qual: string, air_temperature: double, air_temperature_qual: string, USAF: string, WBAN: string, STATION NAME: string, CTRY: string, STATE: string, ICAO: string, LAT: string, LON: string, ELEV(M): string, BEGIN: string, END: string\n",
      "LogicalRDD [year#2, usaf#5, wban#6, date#7, time#8, report_type#9, wind_direction#10, wind_direction_qual#11, wind_observation#12, wind_speed#13, wind_speed_qual#14, air_temperature#15, air_temperature_qual#16, USAF#42, WBAN#43, STATION NAME#44, CTRY#45, STATE#46, ICAO#47, LAT#48, LON#49, ELEV(M)#50, BEGIN#51, END#52], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "LogicalRDD [year#2, usaf#5, wban#6, date#7, time#8, report_type#9, wind_direction#10, wind_direction_qual#11, wind_observation#12, wind_speed#13, wind_speed_qual#14, air_temperature#15, air_temperature_qual#16, USAF#42, WBAN#43, STATION NAME#44, CTRY#45, STATE#46, ICAO#47, LAT#48, LON#49, ELEV(M)#50, BEGIN#51, END#52], false\n",
      "\n",
      "== Physical Plan ==\n",
      "Scan ExistingRDD[year#2,usaf#5,wban#6,date#7,time#8,report_type#9,wind_direction#10,wind_direction_qual#11,wind_observation#12,wind_speed#13,wind_speed_qual#14,air_temperature#15,air_temperature_qual#16,USAF#42,WBAN#43,STATION NAME#44,CTRY#45,STATE#46,ICAO#47,LAT#48,LON#49,ELEV(M)#50,BEGIN#51,END#52]\n"
     ]
    }
   ],
   "source": [
    "cp_weather.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the lineage got lost and is replaced by a `Scan ExistingRDD` which refers to the data in the checkpoint directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform aggregation\n",
    "\n",
    "Now we can perform the aggregation with the checkpointed variant of the joined weather DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate [ctry#45, year#2], [ctry#45, year#2, min(CASE WHEN (air_temperature_qual#16 = 1) THEN air_temperature#15 END) AS min_temp#247, max(CASE WHEN (air_temperature_qual#16 = 1) THEN air_temperature#15 END) AS max_temp#249]\n",
      "+- AnalysisBarrier\n",
      "      +- LogicalRDD [year#2, usaf#5, wban#6, date#7, time#8, report_type#9, wind_direction#10, wind_direction_qual#11, wind_observation#12, wind_speed#13, wind_speed_qual#14, air_temperature#15, air_temperature_qual#16, USAF#42, WBAN#43, STATION NAME#44, CTRY#45, STATE#46, ICAO#47, LAT#48, LON#49, ELEV(M)#50, BEGIN#51, END#52], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "ctry: string, year: int, min_temp: double, max_temp: double\n",
      "Aggregate [ctry#45, year#2], [ctry#45, year#2, min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS min_temp#247, max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS max_temp#249]\n",
      "+- LogicalRDD [year#2, usaf#5, wban#6, date#7, time#8, report_type#9, wind_direction#10, wind_direction_qual#11, wind_observation#12, wind_speed#13, wind_speed_qual#14, air_temperature#15, air_temperature_qual#16, USAF#42, WBAN#43, STATION NAME#44, CTRY#45, STATE#46, ICAO#47, LAT#48, LON#49, ELEV(M)#50, BEGIN#51, END#52], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [ctry#45, year#2], [ctry#45, year#2, min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS min_temp#247, max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS max_temp#249]\n",
      "+- Project [year#2, air_temperature#15, air_temperature_qual#16, CTRY#45]\n",
      "   +- LogicalRDD [year#2, usaf#5, wban#6, date#7, time#8, report_type#9, wind_direction#10, wind_direction_qual#11, wind_observation#12, wind_speed#13, wind_speed_qual#14, air_temperature#15, air_temperature_qual#16, USAF#42, WBAN#43, STATION NAME#44, CTRY#45, STATE#46, ICAO#47, LAT#48, LON#49, ELEV(M)#50, BEGIN#51, END#52], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[ctry#45, year#2], functions=[min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END), max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END)], output=[ctry#45, year#2, min_temp#247, max_temp#249])\n",
      "+- Exchange hashpartitioning(ctry#45, year#2, 200)\n",
      "   +- *(1) HashAggregate(keys=[ctry#45, year#2], functions=[partial_min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END), partial_max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END)], output=[ctry#45, year#2, min#256, max#257])\n",
      "      +- *(1) Project [year#2, air_temperature#15, air_temperature_qual#16, CTRY#45]\n",
      "         +- Scan ExistingRDD[year#2,usaf#5,wban#6,date#7,time#8,report_type#9,wind_direction#10,wind_direction_qual#11,wind_observation#12,wind_speed#13,wind_speed_qual#14,air_temperature#15,air_temperature_qual#16,USAF#42,WBAN#43,STATION NAME#44,CTRY#45,STATE#46,ICAO#47,LAT#48,LON#49,ELEV(M)#50,BEGIN#51,END#52]\n"
     ]
    }
   ],
   "source": [
    "result = cp_weather.groupBy(cp_weather[\"ctry\"], cp_weather[\"year\"]).agg(\n",
    "        min(when(cp_weather.air_temperature_qual == lit(1), cp_weather.air_temperature)).alias('min_temp'),\n",
    "        max(when(cp_weather.air_temperature_qual == lit(1), cp_weather.air_temperature)).alias('max_temp')\n",
    ")\n",
    "\n",
    "result.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the execution plan now essentially only contains the aggregation in three steps (partial aggregation, shuffle, final aggregation). The lineage of the join is not present any more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Unreliable Checkpointing\n",
    "\n",
    "In addition to *reliable* checkpointing, Spark also supports *unreliable* checkpointing, where the data is not stored in HDFS but on the local worker nodes instead using the caching backend.\n",
    "\n",
    "Note that it is stronlgly discouraged to use unreliable checkpointing with dynamic execution mode, where executors can be freed up again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_weather = joined_weather.localCheckpoint(eager=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Checkpoint data\n",
    "\n",
    "Now you can see the checkpointed data in the \"Storage\" section of the web interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform aggregation\n",
    "\n",
    "Now we can perform the aggregation with the checkpointed variant of the joined weather DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate [ctry#45, year#2], [ctry#45, year#2, min(CASE WHEN (air_temperature_qual#16 = 1) THEN air_temperature#15 END) AS min_temp#308, max(CASE WHEN (air_temperature_qual#16 = 1) THEN air_temperature#15 END) AS max_temp#310]\n",
      "+- AnalysisBarrier\n",
      "      +- LogicalRDD [year#2, usaf#5, wban#6, date#7, time#8, report_type#9, wind_direction#10, wind_direction_qual#11, wind_observation#12, wind_speed#13, wind_speed_qual#14, air_temperature#15, air_temperature_qual#16, USAF#42, WBAN#43, STATION NAME#44, CTRY#45, STATE#46, ICAO#47, LAT#48, LON#49, ELEV(M)#50, BEGIN#51, END#52], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "ctry: string, year: int, min_temp: double, max_temp: double\n",
      "Aggregate [ctry#45, year#2], [ctry#45, year#2, min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS min_temp#308, max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS max_temp#310]\n",
      "+- LogicalRDD [year#2, usaf#5, wban#6, date#7, time#8, report_type#9, wind_direction#10, wind_direction_qual#11, wind_observation#12, wind_speed#13, wind_speed_qual#14, air_temperature#15, air_temperature_qual#16, USAF#42, WBAN#43, STATION NAME#44, CTRY#45, STATE#46, ICAO#47, LAT#48, LON#49, ELEV(M)#50, BEGIN#51, END#52], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [ctry#45, year#2], [ctry#45, year#2, min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS min_temp#308, max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END) AS max_temp#310]\n",
      "+- Project [year#2, air_temperature#15, air_temperature_qual#16, CTRY#45]\n",
      "   +- LogicalRDD [year#2, usaf#5, wban#6, date#7, time#8, report_type#9, wind_direction#10, wind_direction_qual#11, wind_observation#12, wind_speed#13, wind_speed_qual#14, air_temperature#15, air_temperature_qual#16, USAF#42, WBAN#43, STATION NAME#44, CTRY#45, STATE#46, ICAO#47, LAT#48, LON#49, ELEV(M)#50, BEGIN#51, END#52], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[ctry#45, year#2], functions=[min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END), max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END)], output=[ctry#45, year#2, min_temp#308, max_temp#310])\n",
      "+- Exchange hashpartitioning(ctry#45, year#2, 200)\n",
      "   +- *(1) HashAggregate(keys=[ctry#45, year#2], functions=[partial_min(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END), partial_max(CASE WHEN (cast(air_temperature_qual#16 as int) = 1) THEN air_temperature#15 END)], output=[ctry#45, year#2, min#317, max#318])\n",
      "      +- *(1) Project [year#2, air_temperature#15, air_temperature_qual#16, CTRY#45]\n",
      "         +- Scan ExistingRDD[year#2,usaf#5,wban#6,date#7,time#8,report_type#9,wind_direction#10,wind_direction_qual#11,wind_observation#12,wind_speed#13,wind_speed_qual#14,air_temperature#15,air_temperature_qual#16,USAF#42,WBAN#43,STATION NAME#44,CTRY#45,STATE#46,ICAO#47,LAT#48,LON#49,ELEV(M)#50,BEGIN#51,END#52]\n"
     ]
    }
   ],
   "source": [
    "result = cpu_weather.groupBy(cpu_weather[\"ctry\"], cpu_weather[\"year\"]).agg(\n",
    "        min(when(cpu_weather.air_temperature_qual == lit(1), cpu_weather.air_temperature)).alias('min_temp'),\n",
    "        max(when(cpu_weather.air_temperature_qual == lit(1), cpu_weather.air_temperature)).alias('max_temp')\n",
    ")\n",
    "\n",
    "result.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ctry</th>\n",
       "      <th>year</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>max_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DA</td>\n",
       "      <td>2003</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EZ</td>\n",
       "      <td>2003</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JA</td>\n",
       "      <td>2003</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>34.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NL</td>\n",
       "      <td>2003</td>\n",
       "      <td>-14.3</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LU</td>\n",
       "      <td>2003</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ctry  year  min_temp  max_temp\n",
       "0   DA  2003     -16.0      30.0\n",
       "1   EZ  2003     -16.0      37.0\n",
       "2   JA  2003      -0.7      34.2\n",
       "3   NL  2003     -14.3      36.0\n",
       "4   LU  2003     -13.0      37.4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Checkpoint cleanup\n",
    "\n",
    "Spark can automatically remove checkpoint directories, if the configuration property `spark.cleaner.referenceTracking.cleanCheckpoints` is set to `True` (default is `False` as of Spark 2.3). Otherwise you have to manually remove checkpoint data from HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 2.3 (Python 3)",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
