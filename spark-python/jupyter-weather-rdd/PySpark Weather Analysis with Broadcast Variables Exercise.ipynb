{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data Analytics\n",
    "This notebook performs some basic weather data analytics using the PySpark RDD interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods\n",
    "First we need some helper methods for converting the raw data into something that we can work with. We decide to use Python dictionaries instead of classes, since custom classes cannot be used within Zeppelin due to serialization issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_float(str):\n",
    "    if len(str) == 0:\n",
    "        return None\n",
    "    try:\n",
    "        return float(str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_station(line):\n",
    "    raw_columns = line.split(',')\n",
    "    columns = [c.replace('\"','') for c in raw_columns]\n",
    "\n",
    "    usaf = columns[0]\n",
    "    wban = columns[1]\n",
    "    name = columns[2]\n",
    "    country = columns[3]\n",
    "    state = columns[4]\n",
    "    icao = columns[5]\n",
    "    latitude = _get_float(columns[6])\n",
    "    longitude = _get_float(columns[7])\n",
    "    elevation = _get_float(columns[8])\n",
    "    date_begin = columns[9]\n",
    "    date_end = columns[10]\n",
    "    return {'usaf':usaf, 'wban':wban, 'name':name, 'country':country, 'state':state, 'icao':icao, 'latitude':latitude, 'longitude':longitude, 'elevation':elevation, 'date_begin':date_begin, 'date_end':date_end }\n",
    "\n",
    "\n",
    "def extract_weather(line):\n",
    "    date = line[15:23]\n",
    "    time = line[23:27]\n",
    "    usaf = line[4:10]\n",
    "    wban = line[10:15]\n",
    "    airTemperatureQuality = line[92] == '1'\n",
    "    airTemperature = float(line[87:92]) / 10\n",
    "    windSpeedQuality = line[69] == '1'\n",
    "    windSpeed = float(line[65:69]) / 10\n",
    "    return {'date':date, 'time':time, 'usaf':usaf, 'wban':wban, 'airTemperatureQuality':airTemperatureQuality, 'airTemperature':airTemperature, 'windSpeedQuality':windSpeedQuality, 'windSpeed':windSpeed }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Functions\n",
    "We want to extract minimum and maximum of wind speed and of temperature. We also want to consider cases where data is not valid (i.e. windSpeedQuality is False or airTemperature is False).\n",
    "\n",
    "We will implement custom aggregation functions that work on dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nullsafe_binop(a, b, op):\n",
    "    if a is None:\n",
    "        return b\n",
    "    if b is None:\n",
    "        return a\n",
    "    return op(a,b)\n",
    "    \n",
    "def nullsafe_min(a, b):\n",
    "    return nullsafe_binop(a, b, min)\n",
    "\n",
    "def nullsafe_max(a, b):\n",
    "    return nullsafe_binop(a, b, max)\n",
    "\n",
    "\n",
    "def reduce_wmm(wmm, data):\n",
    "    \"\"\"\n",
    "    Used for merging in a new weather data set into an existing WeatherMinMax object. The incoming\n",
    "    objects will not be modified, instead a new object will be returned.\n",
    "    :param wmm: WeatherMinMax object\n",
    "    :param data: WeatherData object\n",
    "    :returns: A new WeatherMinMax object\n",
    "    \"\"\"\n",
    "    if data['airTemperatureQuality']:\n",
    "        minTemperature = nullsafe_min(wmm['minTemperature'], data['airTemperature'])\n",
    "        maxTemperature = nullsafe_max(wmm['maxTemperature'], data['airTemperature'])\n",
    "    else:\n",
    "        minTemperature = wmm['minTemperature']\n",
    "        maxTemperature = wmm['maxTemperature']\n",
    "\n",
    "    if data['windSpeedQuality']:\n",
    "        minWindSpeed = nullsafe_min(wmm['minWindSpeed'], data['windSpeed'])\n",
    "        maxWindSpeed = nullsafe_max(wmm['maxWindSpeed'], data['windSpeed'])\n",
    "    else:\n",
    "        minWindSpeed = wmm['minWindSpeed']\n",
    "        maxWindSpeed = wmm['maxWindSpeed']\n",
    "\n",
    "    return { 'minTemperature':minTemperature, 'maxTemperature':maxTemperature, 'minWindSpeed':minWindSpeed, 'maxWindSpeed':maxWindSpeed }\n",
    "\n",
    "\n",
    "def combine_wmm(left, right):\n",
    "    \"\"\"\n",
    "    Used for combining two WeatherMinMax objects into a new WeatherMinMax object\n",
    "    :param self: First WeatherMinMax object\n",
    "    :param other: Second WeatherMinMax object\n",
    "    :returns: A new WeatherMinMax object\n",
    "    \"\"\"\n",
    "    minTemperature = nullsafe_min(left['minTemperature'], right['minTemperature'])\n",
    "    maxTemperature = nullsafe_max(left['maxTemperature'], right['maxTemperature'])\n",
    "    minWindSpeed = nullsafe_min(left['minWindSpeed'], right['minWindSpeed'])\n",
    "    maxWindSpeed = nullsafe_max(left['maxWindSpeed'], right['maxWindSpeed'])\n",
    "\n",
    "    return { 'minTemperature':minTemperature, 'maxTemperature':maxTemperature, 'minWindSpeed':minWindSpeed, 'maxWindSpeed':maxWindSpeed }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Station Index as Broadcast Variable\n",
    "\n",
    "Instead of performing an shuffle join with the station data, we will broadcast the index to all workers and do the lookups locally. This will save us one shuffle.\n",
    "\n",
    "We need to perform the following tasks:\n",
    "\n",
    "1. Load the weather station data from HDFS\n",
    "2. Create appropriate keys from wban and usaf\n",
    "3. Convert the RDD to a local map using collectAsMap()\n",
    "4. Create a broadcast variable from this local map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load station data from '/user/cloudera/data/weather/isd-history.csv' and extract data using extract_station\n",
    "stations = ... \n",
    "\n",
    "# Create a tuple (usaf+wban, station) for every entry in stations\n",
    "station_index_rdd = ...\n",
    "\n",
    "# Transfer the RDD to a local Python dictionary using collectAsMap()\n",
    "station_index_map = ...\n",
    "\n",
    "# Create a broadcast variable from station_index_map\n",
    "station_index_bc = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weather Data\n",
    "Now we can load the weather data, as we have done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather = sc.textFile('/user/cloudera/data/weather/2014').map(lambda line: extract_weather(line))\n",
    "print weather.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Station Data\n",
    "Now we will perform the join of the weather data with the station data. But this time we will use the broadcast variable instead of an explicit shuffle join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The following function will take a weather data object and should return a tuple\n",
    "#   ((country, date), weather)\n",
    "def extract_country_year_weather(weather):\n",
    "    # Extract station_id as usaf + wban from data\n",
    "    station_id = ...\n",
    "    # Lookup station in broadcast variable station_index_bc\n",
    "    station = ...\n",
    "    # Extract country from station\n",
    "    country = ...\n",
    "    # ... and year from weather\n",
    "    year = ...\n",
    "    return ((country, year), weather)\n",
    "\n",
    "# Apply the function to all records\n",
    "weather_per_country_and_year = weather.map(extract_country_year_weather)\n",
    "\n",
    "# Aggregate min/max information per year and country. Nothing has changed here.\n",
    "zero = { 'minTemperature':None, 'maxTemperature':None, 'minWindSpeed':None, 'maxWindSpeed':None }\n",
    "weather_minmax = weather_per_country_and_year.aggregateByKey(zero,reduce_wmm, combine_wmm)\n",
    "\n",
    "print weather_minmax.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Output\n",
    "Again we want to write the result as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_result(row):\n",
    "    (k,v) = row\n",
    "    country = k[0]\n",
    "    year = k[1]\n",
    "    minT = v['minTemperature'] or 0.0\n",
    "    maxT = v['maxTemperature'] or 0.0\n",
    "    minW = v['minWindSpeed'] or 0.0\n",
    "    maxW = v['maxWindSpeed'] or 0.0\n",
    "    line = \"%s,%s,%f,%f,%f,%f\" % (country, year, minT, maxT, minW, maxW)\n",
    "    return line.encode('utf-8')\n",
    "\n",
    "result = weather_minmax.map(format_result).collect()\n",
    "\n",
    "for l in result:\n",
    "    print l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
