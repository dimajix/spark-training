{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Simple Analysis\n",
    "\n",
    "In this step, we perform the first simple analysis of the taxi trip data in order to get a better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwh_basedir = \"/user/hadoop/nyc-dwh\"\n",
    "structured_basedir = dwh_basedir + \"/structured\"\n",
    "refined_basedir = dwh_basedir + \"/refined\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "if not 'spark' in locals():\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\",\"64G\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Geopandas and friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Helper function to fetch background map tiles\n",
    "def add_basemap(ax, zoom, url='http://tile.stamen.com/terrain/tileZ/tileX/tileY.png'):\n",
    "    xmin, xmax, ymin, ymax = ax.axis()\n",
    "    basemap, extent = ctx.bounds2img(xmin, ymin, xmax, ymax, zoom=zoom, url=url)\n",
    "    ax.imshow(basemap, extent=extent, interpolation='bilinear')\n",
    "    # restore original x/y limits\n",
    "    ax.axis((xmin, xmax, ymin, ymax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Taxi Data\n",
    "\n",
    "Now we can read in the taxi data from the structured zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_trips = spark.read.parquet(refined_basedir + \"/taxi-trip\")\n",
    "taxi_trips.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be sure, let us inspect the schema. It should match exactly the specified one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_trips.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create Sample\n",
    "\n",
    "For some actions, we only need a subset of the whole data (some visualizations won't event work with the full data), therefore we create a subsample that is small enough to be handeled efficiently by Python. We'd like to have around 100,000 records in the sample.\n",
    "\n",
    "Spark offers the required functionality to create a *random* sample of the data, but we need to specify a fraction instead of an absolute number. Therefore we first count the number of records and then make up an appropriate fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_trips.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get around 100,000 records, we use a fraction of 0.001. This will give us 170,000 records, which is good enough for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_trips_sample = # YOUR CODE HERE\n",
    "\n",
    "taxi_trips_sample.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simple Geo Visualisation\n",
    "\n",
    "In order to get an understanding of the data, let us first make a geo visualization using some Python functionality. We'd eventually want to draw the pickup locations on top of a map, so we understand the whole area that is served by the taxi cabs. We might want to use this information later when it comes to the ML part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Estimate Extent\n",
    "\n",
    "As a first step, let us estimate a realistic extent of the pickup location. There are some broken records in the data set, which would render the visualisation meaningless, therefore we try to estimate extends such that 95% of all points lie within that border."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = taxi_trips_sample \\\n",
    "    .filter((taxi_trips_sample[\"pickup_longitude\"] > -75) & (taxi_trips_sample[\"pickup_longitude\"] < -65)) \\\n",
    "    .filter((taxi_trips_sample[\"pickup_latitude\"] > 35) & (taxi_trips_sample[\"pickup_latitude\"] < 45)) \\\n",
    "    .stat.approxQuantile([\"pickup_longitude\", \"pickup_latitude\"], [0.025,0.975], 0.01)\n",
    "\n",
    "min_pickup_longitude = quantile[0][0]\n",
    "max_pickup_longitude = quantile[0][1]\n",
    "min_pickup_latitude = quantile[1][0]\n",
    "max_pickup_latitude = quantile[1][1]\n",
    "\n",
    "print(\"min_pickup_longitude=\" + str(min_pickup_longitude))\n",
    "print(\"max_pickup_longitude=\" + str(max_pickup_longitude))\n",
    "print(\"min_pickup_latitude=\" + str(min_pickup_latitude))\n",
    "print(\"max_pickup_latitude=\" + str(max_pickup_latitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Visualize pickup location\n",
    "\n",
    "Now by using some appropriate Python libraries, we can visualize the pickup locations nicely on a map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data contains some bogus coordinates and some (maybe correct) outliers, we limit the area to the extends that we estimated above. This means that we throw away all records which lie outside of the core area (only for this visualization, of course!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = taxi_trips_sample.select(\"pickup_longitude\",\"pickup_latitude\") \\\n",
    "    .filter((taxi_trips_sample[\"pickup_longitude\"] >= min_pickup_longitude) & (taxi_trips_sample[\"pickup_longitude\"] <= max_pickup_longitude)) \\\n",
    "    .filter((taxi_trips_sample[\"pickup_latitude\"] >= min_pickup_latitude) & (taxi_trips_sample[\"pickup_latitude\"] <= max_pickup_latitude)) \\\n",
    "    .toPandas()\n",
    "\n",
    "# Convert DataFrame to GeoDataFrame  \n",
    "coords = pd.Series(zip(df[\"pickup_longitude\"], df[\"pickup_latitude\"]))\n",
    "geo_df = gpd.GeoDataFrame(df, crs = {'init': 'epsg:4326'}, geometry = coords.apply(Point)).to_crs(epsg=3857)\n",
    "\n",
    "# ... and make the plot\n",
    "ax = geo_df.plot(figsize=(15, 10), alpha=0.1)\n",
    "\n",
    "# Add basemap below\n",
    "add_basemap(ax, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the geo extends for later reuse for more visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_min_x, geo_max_x = ax.get_xlim()\n",
    "geo_min_y, geo_max_y = ax.get_ylim()\n",
    "\n",
    "print(\"geo_min_x=\" + str(geo_min_x))\n",
    "print(\"geo_max_x=\" + str(geo_max_x))\n",
    "print(\"geo_min_y=\" + str(geo_min_y))\n",
    "print(\"geo_max_y=\" + str(geo_max_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Simple Questions\n",
    "\n",
    "Using the taxi trips table, we can already answer some simple questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Average Fare per Mile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform aggregation\n",
    "df = # YOUR CODE HERE\n",
    "\n",
    "result = # YOUR CODE HERE\n",
    "\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Average fare per minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform aggregation\n",
    "df = taxi_trips.withColumn(\"fare_per_minute\", taxi_trips[\"total_amount\"]/taxi_trips[\"trip_time_in_secs\"]*60)\n",
    "\n",
    "result = df.select(\n",
    "    f.avg(df[\"fare_per_minute\"]).alias(\"avg_fare_per_minute\"),\n",
    "    f.stddev(df[\"fare_per_minute\"]).alias(\"stddev_fare_per_minute\")\n",
    ")\n",
    "\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Make some Pictures\n",
    "\n",
    "Just to get a rough feeling about the data, we make some pictures of the taxi trip data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Average trips per day of week\n",
    "\n",
    "Let us see if the average number of trips is the same for every week day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the number of trips for every day\n",
    "trips_per_day = # YOUR CODE HERE\n",
    "\n",
    "# Step 2: Calculate average number of trips per day of week\n",
    "result = # YOUR CODE HERE\n",
    "\n",
    "pdf = result.toPandas()\n",
    "\n",
    "plt.figure(figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.bar(pdf[\"pickup_dayofweek\"], pdf[\"avg_count\"], align='center', alpha=0.5)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Day of week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Make a Plot of Fare per Day\n",
    "\n",
    "The next picture contains the total fare amount (including tip and other expenses) for every day in 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate two aggregations\n",
    "#  1. Total fare amount per day\n",
    "#  2. Total number of trips per day\n",
    "daily = # YOUR CODE HERE\n",
    "\n",
    "# Convert to Pandas    \n",
    "pdf = daily.toPandas()\n",
    "\n",
    "# Make a Plot\n",
    "plt.figure(figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(pdf[\"date\"],pdf[\"amount\"], color=\"red\")\n",
    "plt.plot(pdf[\"date\"],pdf[\"count\"], color=\"green\")\n",
    "\n",
    "plt.legend(handles=[\n",
    "    mpatches.Patch(color='red', label='Total Fare Amount per Day'),\n",
    "    mpatches.Patch(color='green', label='Total Number of Trips der Day')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Make a plot of average trips for each hour\n",
    "\n",
    "Let us plot the average number of trips and amount of income per hour. This will be done using a two step aggregation:\n",
    "1. Calculate the total number of trips and total fare for every hour in the whole year\n",
    "2. Calculate the average numbers per hour from this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate totals for every hour of the year\n",
    "hourly_trips = taxi_trips \\\n",
    "    .withColumn(\"date\", f.to_date('pickup_datetime')) \\\n",
    "    .withColumn(\"hour\", f.hour('pickup_datetime')) \\\n",
    "    .groupBy(\"hour\", \"date\").agg(\n",
    "        f.sum(\"total_amount\").alias(\"total_amount\"),\n",
    "        f.count(\"total_amount\").alias(\"total_count\")\n",
    "    )\n",
    "\n",
    "# Step 2: Calculate average values per hour of day\n",
    "hourly_avg = hourly_trips \\\n",
    "    .groupBy(\"hour\").agg(\n",
    "        f.avg(\"total_amount\").alias(\"avg_amount\"),\n",
    "        f.avg(\"total_count\").alias(\"avg_count\")\n",
    "    )\\\n",
    "    .orderBy(\"hour\")\n",
    "\n",
    "# Convert to Pandas    \n",
    "pdf = hourly_avg.toPandas()\n",
    "\n",
    "# Make a Plot\n",
    "plt.figure(figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(pdf[\"hour\"],pdf[\"avg_amount\"], color=\"red\")\n",
    "plt.plot(pdf[\"hour\"],pdf[\"avg_count\"], color=\"green\")\n",
    "\n",
    "plt.legend(handles=[\n",
    "    mpatches.Patch(color='red', label='Average Total Fare per Hour'),\n",
    "    mpatches.Patch(color='green', label='Average Trip Count per Hour')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Passenger Counts\n",
    "\n",
    "Another simple question is a histogram of the passenger count of all trips. Note that again the data contains some bogus data, therefore we limit the analysis to records with a passenger count less than 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = taxi_trips \\\n",
    "    .filter(f.col(\"passenger_count\") < 20) \\\n",
    "    .groupBy(\"passenger_count\") \\\n",
    "    .count()\n",
    "pdf = result.toPandas()\n",
    "\n",
    "plt.figure(figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.bar(pdf[\"passenger_count\"], pdf[\"count\"], align='center', alpha=0.5)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Number of Passengers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Average income by hour by driver\n",
    "\n",
    "The next plot is a slight variation of the previous one, focusing on the individual driver. The question is, how much money does a driver make on average for a specific hour of the day. Again, this requires a two step aggregation\n",
    "\n",
    "1. Calculate the total amount for every hour of the year for each driver\n",
    "2. Calculate the average income per hour over all days and all drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate totals per driver per hour per day\n",
    "hourly_totals = taxi_trips \\\n",
    "    .withColumn(\"date\", f.to_date('pickup_datetime')) \\\n",
    "    .withColumn(\"hour\", f.hour('pickup_datetime')) \\\n",
    "    .groupBy(\"date\", \"hour\", \"hack_license\").agg(\n",
    "        f.sum(\"fare_amount\").alias(\"fare_amount\"),\n",
    "        f.sum(\"tip_amount\").alias(\"tip_amount\"),\n",
    "        f.count(\"fare_amount\").alias(\"trip_count\")\n",
    "    )\n",
    "\n",
    "# Step 2: Calculate average per hour\n",
    "hourly_driver_avg = hourly_totals \\\n",
    "    .groupBy(\"hour\").agg(\n",
    "        f.avg(\"fare_amount\").alias(\"avg_fare_amount\"),\n",
    "        f.avg(\"tip_amount\").alias(\"avg_tip_amount\"),\n",
    "        f.avg(\"trip_count\").alias(\"avg_trip_count\")\n",
    "    ) \\\n",
    "    .orderBy(\"hour\")\n",
    "\n",
    "# Convert to Pandas    \n",
    "pdf = hourly_driver_avg.toPandas()\n",
    "\n",
    "# Make a Plot\n",
    "plt.figure(figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(pdf[\"hour\"],pdf[\"avg_fare_amount\"], color=\"red\")\n",
    "plt.plot(pdf[\"hour\"],pdf[\"avg_tip_amount\"], color=\"green\")\n",
    "plt.plot(pdf[\"hour\"],pdf[\"avg_trip_count\"], color=\"blue\")\n",
    "\n",
    "plt.legend(handles=[\n",
    "    mpatches.Patch(color='red', label='Average Fare Amount per Hour per Driver'),\n",
    "    mpatches.Patch(color='green', label='Average Tip Amount per Hour per Driver'),\n",
    "    mpatches.Patch(color='blue', label='Average Trip Count per Hour per Driver')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Average income per day\n",
    "\n",
    "The next plot is a slight variation of the previous one, now looking at the income on a whole day. The question is, how much money does a driver make on average for a specific day. Again, this requires a two step aggregation\n",
    "\n",
    "1. Calculate the total amount for every day of the year for each driver\n",
    "2. Calculate the average income per day over all days and all drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate totals per driver per date\n",
    "daily_totals = taxi_trips \\\n",
    "    .withColumn(\"date\", f.to_date('pickup_datetime')) \\\n",
    "    .groupBy(\"date\", \"hack_license\").agg(\n",
    "        f.sum(\"total_amount\").alias(\"amount\"),\n",
    "        f.count(\"total_amount\").alias(\"count\")\n",
    "    )\n",
    "\n",
    "# Step 2: Calculate average per date \n",
    "daily_average = daily_totals \\\n",
    "    .groupBy(\"date\").agg(\n",
    "        f.avg(\"amount\").alias(\"avg_amount\"),\n",
    "        f.avg(\"count\").alias(\"avg_count\")\n",
    "    ) \\\n",
    "    .orderBy(\"date\")\n",
    "\n",
    "# Convert to Pandas    \n",
    "pdf = daily_average.toPandas()\n",
    "\n",
    "# Make a Plot\n",
    "plt.figure(figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(pdf[\"date\"],pdf[\"avg_amount\"], color=\"red\")\n",
    "plt.plot(pdf[\"date\"],pdf[\"avg_count\"], color=\"blue\")\n",
    "\n",
    "plt.legend(handles=[\n",
    "    mpatches.Patch(color='red', label='Average Fare Amount per Day per Driver'),\n",
    "    mpatches.Patch(color='blue', label='Average Trip Count per Day per Driver')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Tip by passenger count\n",
    "\n",
    "Does the tip depend on the number of passengers? Let us display the average tip amount for each number of passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_by_passengers = taxi_trips \\\n",
    "    .filter(taxi_trips[\"passenger_count\"] < 10) \\\n",
    "    .groupBy(\"passenger_count\").agg(\n",
    "        f.avg(\"tip_amount\").alias(\"tip_amount\")\n",
    "    ) \\\n",
    "    .orderBy(\"passenger_count\")\n",
    "\n",
    "# Convert to Pandas    \n",
    "pdf = tip_by_passengers.toPandas()\n",
    "\n",
    "# Make a Plot\n",
    "plt.figure(figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.bar(pdf[\"passenger_count\"], pdf[\"tip_amount\"], align='center', alpha=0.5)\n",
    "plt.ylabel('Tip Amount')\n",
    "plt.title('Number of Passengers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Preaggregated Taxi Trips\n",
    "\n",
    "Before we start to include additional data sets from other sources, let us first focus a reasonable question which we'd like to give an answer to with machine learning.\n",
    "\n",
    "We are not so much interested into the individual trips, but we'd like to understand at which time a driver can make most money. We already saw in the pictures above, that the average amount of money per hour per driver doesn't vary very much, although most money seems to be made in the evening hours. Unfortunately these numbers do not neccessarily tell the whole truth, since we don't have any information about how long a driver was actually working.\n",
    "\n",
    "So the question is: *\"Can we predict the overall fares for a specific hour on a specific day?\"* We will refine that question a little bit and clarify what information may be used to create the prediction, such that it makes sense from a business point of view.\n",
    "\n",
    "We now prepare the joined trip data to contain data for precisely this question - we will remove the drivers hack license and medallion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Extend Information\n",
    "\n",
    "As a first step, we add some more columns:\n",
    "* **date** and **hour** - The pickup date and hour (without minutes or seconds)\n",
    "* **lat_idx** and **long_idx** - We map the whole geo range into a grid and these two columns contains logical coordinates in this grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pickup_longitude=-74.007698\n",
    "max_pickup_longitude=-73.776711\n",
    "min_pickup_latitude=40.706902\n",
    "max_pickup_latitude=40.799072\n",
    "\n",
    "longitude_grid_size = 10\n",
    "latitude_grid_size = 5\n",
    "longitude_grid_diff = (max_pickup_longitude - min_pickup_longitude) / longitude_grid_size\n",
    "latitude_grid_diff = (max_pickup_latitude - min_pickup_latitude) / latitude_grid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_trips = taxi_trips \\\n",
    "    .withColumn(\"date\", f.to_date(taxi_trips[\"pickup_datetime\"])) \\\n",
    "    .withColumn(\"hour\", f.hour(taxi_trips[\"pickup_datetime\"])) \\\n",
    "    .withColumn(\"lat_idx\", f.rint((taxi_trips[\"pickup_latitude\"] - min_pickup_latitude)/latitude_grid_diff)) \\\n",
    "    .withColumn(\"long_idx\", f.rint((taxi_trips[\"pickup_longitude\"] - min_pickup_longitude)/longitude_grid_diff)) \\\n",
    "    .withColumn(\"lat_idx\", f.when((f.col(\"lat_idx\") >= 0) & (f.col(\"lat_idx\") < latitude_grid_size), f.col(\"lat_idx\")).otherwise(-1).cast(\"int\")) \\\n",
    "    .withColumn(\"long_idx\", f.when((f.col(\"long_idx\") >= 0) & (f.col(\"long_idx\") < longitude_grid_size), f.col(\"long_idx\")).otherwise(-1).cast(\"int\")) \\\n",
    "\n",
    "extended_trips.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Preaggregate and Store into Refined Zone\n",
    "\n",
    "Now we preaggregate the extended data using the following dimensions\n",
    "* **date** and **hour**\n",
    "* **lat_idx** and **long_idx**\n",
    "\n",
    "In addition to the dimensions, the result will aggregate (sum up) the following metrics\n",
    "* **passenger_count**\n",
    "* **fare_amount**\n",
    "* **tip_amount**\n",
    "* **total_amount**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_taxi_trips = # YOUR CODE HERE\n",
    "\n",
    "hourly_taxi_trips.write.mode(\"overwrite\").parquet(refined_basedir + \"/taxi-trips-hourly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_taxi_trips = spark.read.parquet(refined_basedir + \"/taxi-trips-hourly\")\n",
    "hourly_taxi_trips.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. More Pictures\n",
    "\n",
    "Using the preaggregated data set, we can now draw some more pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Daily Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = hourly_taxi_trips \\\n",
    "    .groupBy(\"date\").agg(\n",
    "        f.sum(\"fare_amount\").alias(\"fare_amount\"),\n",
    "        f.sum(\"tip_amount\").alias(\"tip_amount\"),\n",
    "        f.sum(\"total_amount\").alias(\"total_amount\"),\n",
    "        f.sum(\"trip_count\").alias(\"trip_count\")\n",
    "    )\\\n",
    "    .orderBy(\"date\")\n",
    "\n",
    "# Convert to Pandas    \n",
    "pdf = daily.toPandas()\n",
    "\n",
    "# Make a Plot\n",
    "plt.figure(figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(pdf[\"date\"],pdf[\"fare_amount\"], color=\"red\")\n",
    "plt.plot(pdf[\"date\"],pdf[\"tip_amount\"], color=\"green\")\n",
    "plt.plot(pdf[\"date\"],pdf[\"total_amount\"], color=\"blue\")\n",
    "plt.plot(pdf[\"date\"],pdf[\"trip_count\"], color=\"violet\")\n",
    "\n",
    "plt.legend(handles=[\n",
    "    mpatches.Patch(color='red', label='Fare Amount'),\n",
    "    mpatches.Patch(color='green', label='Tip Amount'),\n",
    "    mpatches.Patch(color='blue', label='Total Amount'),\n",
    "    mpatches.Patch(color='violet', label='Trip Count')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Average fare and tip per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = hourly_taxi_trips \\\n",
    "    .groupBy(\"hour\").agg(\n",
    "        f.avg(hourly_taxi_trips[\"fare_amount\"] / hourly_taxi_trips[\"trip_count\"]).alias(\"avg_fare_amount\"),\n",
    "        f.avg(hourly_taxi_trips[\"tip_amount\"] / hourly_taxi_trips[\"trip_count\"]).alias(\"avg_tip_amount\")\n",
    "    )\\\n",
    "    .orderBy(\"hour\")\n",
    "\n",
    "# Convert to Pandas    \n",
    "pdf = hourly.toPandas()\n",
    "\n",
    "# Make a Plot\n",
    "plt.figure(figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(pdf[\"hour\"],pdf[\"avg_fare_amount\"], color=\"red\")\n",
    "plt.plot(pdf[\"hour\"],pdf[\"avg_tip_amount\"], color=\"green\")\n",
    "\n",
    "plt.legend(handles=[\n",
    "    mpatches.Patch(color='red', label='Average Fare Amount'),\n",
    "    mpatches.Patch(color='green', label='Average Tip Amount')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 2.4 (Python 3.7)",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
