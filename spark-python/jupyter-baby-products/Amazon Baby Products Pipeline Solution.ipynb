{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "First we load data from HDFS. It is stored as a trivial CSV file with three columns\n",
    "1. product name\n",
    "2. review text\n",
    "3. rating (1 - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>review</td>\n",
       "      <td>rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                                               name   \n",
       "1                           Planetwise Flannel Wipes   \n",
       "2                              Planetwise Wipe Pouch   \n",
       "3                Annas Dream Full Quilt with 2 Shams   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0                                             review  rating  \n",
       "1  These flannel wipes are OK, but in my opinion ...       3  \n",
       "2  it came early and was not disappointed. i love...       5  \n",
       "3  Very soft and comfortable and warmer than it l...       5  \n",
       "4  This is a product well worth the purchase.  I ...       5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema =  StructType([\n",
    "    StructField('name',StringType(),True),\n",
    "    StructField('review',StringType(), True),\n",
    "    StructField('rating',StringType(), True),\n",
    "])\n",
    "\n",
    "raw_data = spark.read.schema(schema).csv(\"s3a://dimajix-training/data/amazon_baby\")\n",
    "raw_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Cache Data\n",
    "\n",
    "We need to convert the \"rating\" columns to an integer - but this will obviously fail for the first record, as this one contains the CSV header. So we need to perform some cleanup after trying to convert the data.\n",
    "\n",
    "For helping distributing the workload, we repartition the DataFrame and also cache it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cloud b Gentle Giraffe On The Go Travel Sound ...</td>\n",
       "      <td>This is the best item ever to calm your baby t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evenflo Tribute 5 Convertible Car Seat, Ella</td>\n",
       "      <td>Cheap. Feels cheap too. Doesn't feel sturdy. H...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Britax Parkway SGL Booster Seat, Cardinal</td>\n",
       "      <td>Great product, well made, comfortable, and bei...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boon Scrubble Interchangeable Bath Toy Squirt ...</td>\n",
       "      <td>These are great.  They are a tad bit hard to p...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summer Infant By Your Side Sleeper Portable Be...</td>\n",
       "      <td>\"I just purchased this co sleeper, so I will l...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cloud b Gentle Giraffe On The Go Travel Sound ...   \n",
       "1       Evenflo Tribute 5 Convertible Car Seat, Ella   \n",
       "2          Britax Parkway SGL Booster Seat, Cardinal   \n",
       "3  Boon Scrubble Interchangeable Bath Toy Squirt ...   \n",
       "4  Summer Infant By Your Side Sleeper Portable Be...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  This is the best item ever to calm your baby t...       5  \n",
       "1  Cheap. Feels cheap too. Doesn't feel sturdy. H...       3  \n",
       "2  Great product, well made, comfortable, and bei...       5  \n",
       "3  These are great.  They are a tad bit hard to p...       5  \n",
       "4  \"I just purchased this co sleeper, so I will l...       4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = raw_data.withColumn('rating',col('rating').cast(IntegerType())) \\\n",
    "    .filter(col('rating').isNotNull()) \\\n",
    "    .filter(col('review').isNotNull()) \\\n",
    "    .repartition(31) \\\n",
    "    .cache()\n",
    "\n",
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train Data / Test Data\n",
    "\n",
    "Now let's do the usual split of our data into a training data set and a validation data set. Let's use 80% of all reviews for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 139461\n",
      "test_data: 34861\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = data.randomSplit([0.8,0.2], seed=1)\n",
    "\n",
    "print(\"train_data: %d\" % train_data.count())\n",
    "print(\"test_data: %d\" % test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Transformer for Removing Punctuations\n",
    "\n",
    "We need a custom Transformer to build the pipeline. The transformer should remove all punctuations from a given column containing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    import string\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "class PunctuationCleanupTransformer(Transformer):\n",
    "    def __init__(self, inputCol, outputCol):\n",
    "        \"\"\"\n",
    "        Constructor of PunctuationCleanupTransformer which takes two arguments:\n",
    "        inputCol - name of input column\n",
    "        outputCol - name of output column\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        \"\"\"\n",
    "        Protecetd _transform method which will be called by the public transform\n",
    "        method. You should not call this method directly.\n",
    "        \"\"\"\n",
    "        remove_punctuation_udf = udf(remove_punctuations, StringType())\n",
    "        return dataset.withColumn(self.outputCol, remove_punctuation_udf(self.inputCol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Transformer\n",
    "\n",
    "Lets create an instance of the Transformer and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cloud b Gentle Giraffe On The Go Travel Sound ...</td>\n",
       "      <td>This is the best item ever to calm your baby t...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is the best item ever to calm your baby t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evenflo Tribute 5 Convertible Car Seat, Ella</td>\n",
       "      <td>Cheap. Feels cheap too. Doesn't feel sturdy. H...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cheap  Feels cheap too  Doesn t feel sturdy  H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Britax Parkway SGL Booster Seat, Cardinal</td>\n",
       "      <td>Great product, well made, comfortable, and bei...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great product  well made  comfortable  and bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boon Scrubble Interchangeable Bath Toy Squirt ...</td>\n",
       "      <td>These are great.  They are a tad bit hard to p...</td>\n",
       "      <td>5</td>\n",
       "      <td>These are great   They are a tad bit hard to p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cloud b Gentle Giraffe On The Go Travel Sound ...   \n",
       "1       Evenflo Tribute 5 Convertible Car Seat, Ella   \n",
       "2          Britax Parkway SGL Booster Seat, Cardinal   \n",
       "3  Boon Scrubble Interchangeable Bath Toy Squirt ...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  This is the best item ever to calm your baby t...       5   \n",
       "1  Cheap. Feels cheap too. Doesn't feel sturdy. H...       3   \n",
       "2  Great product, well made, comfortable, and bei...       5   \n",
       "3  These are great.  They are a tad bit hard to p...       5   \n",
       "\n",
       "                                        clean_review  \n",
       "0  This is the best item ever to calm your baby t...  \n",
       "1  Cheap  Feels cheap too  Doesn t feel sturdy  H...  \n",
       "2  Great product  well made  comfortable  and bei...  \n",
       "3  These are great   They are a tad bit hard to p...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner = PunctuationCleanupTransformer(inputCol='review', outputCol='clean_review')\n",
    "clean_data = cleaner.transform(data)\n",
    "\n",
    "clean_data.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Transformer for Stemming\n",
    "\n",
    "We need to stem words, and for doing so we use the Python NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stem_word(words):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(word) for word in words]\n",
    "\n",
    "\n",
    "class PorterStemmerTransformer(Transformer):\n",
    "    def __init__(self, inputCol, outputCol):\n",
    "        \"\"\"\n",
    "        Constructor of PorterStemmerTransformer which takes two arguments:\n",
    "        inputCol - name of input column\n",
    "        outputCol - name of output column\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        \"\"\"\n",
    "        Protecetd _transform method which will be called by the public transform\n",
    "        method. You should not call this method directly.\n",
    "        \"\"\"\n",
    "        stem_word_udf = udf(stem_word, ArrayType(StringType()))\n",
    "        return dataset.withColumn(self.outputCol, stem_word_udf(self.inputCol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Transformer\n",
    "\n",
    "Again we want to test the `PorterStemmerTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>words</th>\n",
       "      <th>stemmed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cloud b Gentle Giraffe On The Go Travel Sound ...</td>\n",
       "      <td>This is the best item ever to calm your baby t...</td>\n",
       "      <td>5</td>\n",
       "      <td>[this, is, the, best, item, ever, to, calm, yo...</td>\n",
       "      <td>[thi, is, the, best, item, ever, to, calm, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evenflo Tribute 5 Convertible Car Seat, Ella</td>\n",
       "      <td>Cheap. Feels cheap too. Doesn't feel sturdy. H...</td>\n",
       "      <td>3</td>\n",
       "      <td>[cheap., feels, cheap, too., doesn't, feel, st...</td>\n",
       "      <td>[cheap., feel, cheap, too., doesn't, feel, stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Britax Parkway SGL Booster Seat, Cardinal</td>\n",
       "      <td>Great product, well made, comfortable, and bei...</td>\n",
       "      <td>5</td>\n",
       "      <td>[great, product,, well, made,, comfortable,, a...</td>\n",
       "      <td>[great, product,, well, made,, comfortable,, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boon Scrubble Interchangeable Bath Toy Squirt ...</td>\n",
       "      <td>These are great.  They are a tad bit hard to p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[these, are, great., , they, are, a, tad, bit,...</td>\n",
       "      <td>[these, are, great., , they, are, a, tad, bit,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cloud b Gentle Giraffe On The Go Travel Sound ...   \n",
       "1       Evenflo Tribute 5 Convertible Car Seat, Ella   \n",
       "2          Britax Parkway SGL Booster Seat, Cardinal   \n",
       "3  Boon Scrubble Interchangeable Bath Toy Squirt ...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  This is the best item ever to calm your baby t...       5   \n",
       "1  Cheap. Feels cheap too. Doesn't feel sturdy. H...       3   \n",
       "2  Great product, well made, comfortable, and bei...       5   \n",
       "3  These are great.  They are a tad bit hard to p...       5   \n",
       "\n",
       "                                               words  \\\n",
       "0  [this, is, the, best, item, ever, to, calm, yo...   \n",
       "1  [cheap., feels, cheap, too., doesn't, feel, st...   \n",
       "2  [great, product,, well, made,, comfortable,, a...   \n",
       "3  [these, are, great., , they, are, a, tad, bit,...   \n",
       "\n",
       "                                      stemmed_review  \n",
       "0  [thi, is, the, best, item, ever, to, calm, you...  \n",
       "1  [cheap., feel, cheap, too., doesn't, feel, stu...  \n",
       "2  [great, product,, well, made,, comfortable,, a...  \n",
       "3  [these, are, great., , they, are, a, tad, bit,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import *\n",
    "\n",
    "# First we need to Tokenize each line. In order to perform this task, we implement the following steps\n",
    "# 1. Instantiate a Tokenizer instance from pyspark.ml.feature\n",
    "# 2. Transform the raw data using the tokenizer\n",
    "tokenizer = Tokenizer(inputCol='review', outputCol='words')\n",
    "tokenized_data = tokenizer.transform(data)\n",
    "\n",
    "# Then we can instantiate the Stemmer and use it on the words\n",
    "stemmer = PorterStemmerTransformer(inputCol='words', outputCol='stemmed_review')\n",
    "stemmed_data = stemmer.transform(tokenized_data)\n",
    "\n",
    "stemmed_data.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ML Pipeline\n",
    "\n",
    "Now we have all components for creating an initial ML Pipeline. Remember that we have been using the following components before\n",
    "\n",
    "* PunctuationCleanupTransformer - remove punctuations from reviews\n",
    "* Tokenizer - for splitting reviews into words\n",
    "* StopWordRemover - for removing stop words\n",
    "* PorterStemmerTransformer - for stemming words\n",
    "* NGram - for creating NGrams (we'll use two words per n-gram)\n",
    "* CountVectorizer - for creating bag-of-word features from the words\n",
    "* IDF - for creating TF-IDF features from the NGram counts\n",
    "* LogisticRegression - for creating the real model\n",
    "\n",
    "You also need to transform the incoming rating (1-5) to a sentiment (0 or 1) and you need to drop reviews with a rating of 3. This can be done using one ore more SQLTransformer instances. Inside the SQLTransformer instance you simply write SQL code and access the current DataFrame via `__THIS__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "\n",
    "stopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "\n",
    "stages = [\n",
    "    PunctuationCleanupTransformer(inputCol='review', outputCol='clean_review'),\n",
    "    SQLTransformer(statement='SELECT *,CASE WHEN rating < 3 THEN 0.0 ELSE 1.0 END AS sentiment FROM __THIS__ WHERE rating <> 3'),\n",
    "    Tokenizer(inputCol='clean_review', outputCol='words'),\n",
    "    StopWordsRemover(inputCol='words', outputCol='vwords', stopWords=stopWords),\n",
    "    PorterStemmerTransformer(inputCol='vwords', outputCol='stems'),\n",
    "    NGram(inputCol='stems', outputCol='ngrams', n=3),\n",
    "    CountVectorizer(inputCol='ngrams', outputCol='tf', minDF=2.0),\n",
    "    IDF(inputCol='tf', outputCol='features'),\n",
    "    LogisticRegression(featuresCol='features',labelCol='sentiment')\n",
    "]\n",
    "pipe = Pipeline(stages = stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Pipeline Model\n",
    "Using training data, we create a PipelineModel by fitting the Pipeline to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Data\n",
    "\n",
    "Let us do some predictions of the test data using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "      <th>vwords</th>\n",
       "      <th>stems</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>tf</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>I LOVE the CubeIt! FunBites!!!! This is perfec...</td>\n",
       "      <td>5</td>\n",
       "      <td>I LOVE the CubeIt  FunBites     This is perfec...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, love, the, cubeit, , funbites, , , , , thi...</td>\n",
       "      <td>[love, cubeit, , funbites, , , , , perfect, , ...</td>\n",
       "      <td>[love, cubeit, , funbit, , , , , perfect, , es...</td>\n",
       "      <td>[love cubeit , cubeit  funbit,  funbit , funbi...</td>\n",
       "      <td>(2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(3.658600720360723, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[-158.8174727939285, 158.8174727939285]</td>\n",
       "      <td>[1.0627911657850075e-69, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>I'm all for being 'green'; this bag is perfect...</td>\n",
       "      <td>5</td>\n",
       "      <td>I m all for being  green   this bag is perfect...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, m, all, for, being, , green, , , this, bag...</td>\n",
       "      <td>[m, , green, , , bag, perfect, holding, sandwi...</td>\n",
       "      <td>[m, , green, , , bag, perfect, hold, sandwich,...</td>\n",
       "      <td>[m  green,  green , green  ,   bag,  bag perfe...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-62.64797630192351, 62.64797630192351]</td>\n",
       "      <td>[6.1991135245042445e-28, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#1 Adjustable Back Seat Baby Safety Mirror - E...</td>\n",
       "      <td>Great product and very good quality! Fits easi...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great product and very good quality  Fits easi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[great, product, and, very, good, quality, , f...</td>\n",
       "      <td>[great, product, good, quality, , fits, easily...</td>\n",
       "      <td>[great, product, good, qualiti, , fit, easili,...</td>\n",
       "      <td>[great product good, product good qualiti, goo...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-92.92631076516145, 92.92631076516145]</td>\n",
       "      <td>[4.3915315891365726e-41, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#76 Hot Pink baby leg warmers for baby or girl...</td>\n",
       "      <td>these leg-warmers are great! they fit a bit ro...</td>\n",
       "      <td>5</td>\n",
       "      <td>these leg warmers are great  they fit a bit ro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[these, leg, warmers, are, great, , they, fit,...</td>\n",
       "      <td>[leg, warmers, great, , fit, bit, roomy, 4, mo...</td>\n",
       "      <td>[leg, warmer, great, , fit, bit, roomi, 4, mon...</td>\n",
       "      <td>[leg warmer great, warmer great , great  fit, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-48.550567254874686, 48.550567254874686]</td>\n",
       "      <td>[8.21781855294416e-22, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;quot;Sweet Pink Sherbet Hoodie Towel&amp;quot; --...</td>\n",
       "      <td>Bought this as a gift for my 3yr old granddaug...</td>\n",
       "      <td>4</td>\n",
       "      <td>Bought this as a gift for my 3yr old granddaug...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[bought, this, as, a, gift, for, my, 3yr, old,...</td>\n",
       "      <td>[bought, gift, 3yr, old, granddaughter, , , dr...</td>\n",
       "      <td>[bought, gift, 3yr, old, granddaught, , , dri,...</td>\n",
       "      <td>[bought gift 3yr, gift 3yr old, 3yr old grandd...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(1.8293003601803615, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-105.00144560466066, 105.00144560466066]</td>\n",
       "      <td>[2.50294658809125e-46, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>- \\t New Umbra Bungee Wallet Business Card Cas...</td>\n",
       "      <td>Big and bulky. The bungee lid is awkward. Stic...</td>\n",
       "      <td>1</td>\n",
       "      <td>Big and bulky  The bungee lid is awkward  Stic...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[big, and, bulky, , the, bungee, lid, is, awkw...</td>\n",
       "      <td>[big, bulky, , bungee, lid, awkward, , stick, ...</td>\n",
       "      <td>[big, bulki, , bunge, lid, awkward, , stick, t...</td>\n",
       "      <td>[big bulki , bulki  bunge,  bunge lid, bunge l...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-4.325467740946893, 4.325467740946893]</td>\n",
       "      <td>[0.01305468266162946, 0.9869453173383707]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10/pk - Enfamil Disposable Slow-Flow Soft Nipples</td>\n",
       "      <td>I love these nipples and they make it very eas...</td>\n",
       "      <td>5</td>\n",
       "      <td>I love these nipples and they make it very eas...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, love, these, nipples, and, they, make, it,...</td>\n",
       "      <td>[love, nipples, make, easy, baby, drink, wonde...</td>\n",
       "      <td>[love, nippl, make, easi, babi, drink, wonder,...</td>\n",
       "      <td>[love nippl make, nippl make easi, make easi b...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-31.811646690049752, 31.811646690049752]</td>\n",
       "      <td>[1.5288940209156156e-14, 0.9999999999999847]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10PC BLACK WHITE &amp;amp; RED CRIB NURSERY BEDDIN...</td>\n",
       "      <td>I washed and dried the set, as instructed, and...</td>\n",
       "      <td>4</td>\n",
       "      <td>I washed and dried the set  as instructed  and...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, washed, and, dried, the, set, , as, instru...</td>\n",
       "      <td>[washed, dried, set, , instructed, , white, ma...</td>\n",
       "      <td>[wash, dri, set, , instruct, , white, materi, ...</td>\n",
       "      <td>[wash dri set, dri set , set  instruct,  instr...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-41.08744355268045, 41.08744355268045]</td>\n",
       "      <td>[1.4320229876135606e-18, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12 Pack Fuzzi Bunz One-Size Cloth Diapers GEND...</td>\n",
       "      <td>I ordered a 12-pack of Fuzzi-Bunz One Size dia...</td>\n",
       "      <td>4</td>\n",
       "      <td>I ordered a 12 pack of Fuzzi Bunz One Size dia...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, ordered, a, 12, pack, of, fuzzi, bunz, one...</td>\n",
       "      <td>[ordered, 12, pack, fuzzi, bunz, one, size, di...</td>\n",
       "      <td>[order, 12, pack, fuzzi, bunz, one, size, diap...</td>\n",
       "      <td>[order 12 pack, 12 pack fuzzi, pack fuzzi bunz...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[46.82453602221994, -46.82453602221994]</td>\n",
       "      <td>[1.0, 4.6170267192573065e-21]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1st Bday Girl Autograph Bear</td>\n",
       "      <td>I loved the idea of an autograph teddy bear th...</td>\n",
       "      <td>4</td>\n",
       "      <td>I loved the idea of an autograph teddy bear th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, loved, the, idea, of, an, autograph, teddy...</td>\n",
       "      <td>[loved, idea, autograph, teddy, bear, daughter...</td>\n",
       "      <td>[love, idea, autograph, teddi, bear, daughter,...</td>\n",
       "      <td>[love idea autograph, idea autograph teddi, au...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-100.96032033879625, 100.96032033879625]</td>\n",
       "      <td>[1.4239344120021173e-44, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  #1 Adjustable Back Seat Baby Safety Mirror - E...   \n",
       "3  #76 Hot Pink baby leg warmers for baby or girl...   \n",
       "4  &quot;Sweet Pink Sherbet Hoodie Towel&quot; --...   \n",
       "5  - \\t New Umbra Bungee Wallet Business Card Cas...   \n",
       "6  10/pk - Enfamil Disposable Slow-Flow Soft Nipples   \n",
       "7  10PC BLACK WHITE &amp; RED CRIB NURSERY BEDDIN...   \n",
       "8  12 Pack Fuzzi Bunz One-Size Cloth Diapers GEND...   \n",
       "9                       1st Bday Girl Autograph Bear   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  I LOVE the CubeIt! FunBites!!!! This is perfec...       5   \n",
       "1  I'm all for being 'green'; this bag is perfect...       5   \n",
       "2  Great product and very good quality! Fits easi...       5   \n",
       "3  these leg-warmers are great! they fit a bit ro...       5   \n",
       "4  Bought this as a gift for my 3yr old granddaug...       4   \n",
       "5  Big and bulky. The bungee lid is awkward. Stic...       1   \n",
       "6  I love these nipples and they make it very eas...       5   \n",
       "7  I washed and dried the set, as instructed, and...       4   \n",
       "8  I ordered a 12-pack of Fuzzi-Bunz One Size dia...       4   \n",
       "9  I loved the idea of an autograph teddy bear th...       4   \n",
       "\n",
       "                                        clean_review sentiment  \\\n",
       "0  I LOVE the CubeIt  FunBites     This is perfec...       1.0   \n",
       "1  I m all for being  green   this bag is perfect...       1.0   \n",
       "2  Great product and very good quality  Fits easi...       1.0   \n",
       "3  these leg warmers are great  they fit a bit ro...       1.0   \n",
       "4  Bought this as a gift for my 3yr old granddaug...       1.0   \n",
       "5  Big and bulky  The bungee lid is awkward  Stic...       0.0   \n",
       "6  I love these nipples and they make it very eas...       1.0   \n",
       "7  I washed and dried the set  as instructed  and...       1.0   \n",
       "8  I ordered a 12 pack of Fuzzi Bunz One Size dia...       1.0   \n",
       "9  I loved the idea of an autograph teddy bear th...       1.0   \n",
       "\n",
       "                                               words  \\\n",
       "0  [i, love, the, cubeit, , funbites, , , , , thi...   \n",
       "1  [i, m, all, for, being, , green, , , this, bag...   \n",
       "2  [great, product, and, very, good, quality, , f...   \n",
       "3  [these, leg, warmers, are, great, , they, fit,...   \n",
       "4  [bought, this, as, a, gift, for, my, 3yr, old,...   \n",
       "5  [big, and, bulky, , the, bungee, lid, is, awkw...   \n",
       "6  [i, love, these, nipples, and, they, make, it,...   \n",
       "7  [i, washed, and, dried, the, set, , as, instru...   \n",
       "8  [i, ordered, a, 12, pack, of, fuzzi, bunz, one...   \n",
       "9  [i, loved, the, idea, of, an, autograph, teddy...   \n",
       "\n",
       "                                              vwords  \\\n",
       "0  [love, cubeit, , funbites, , , , , perfect, , ...   \n",
       "1  [m, , green, , , bag, perfect, holding, sandwi...   \n",
       "2  [great, product, good, quality, , fits, easily...   \n",
       "3  [leg, warmers, great, , fit, bit, roomy, 4, mo...   \n",
       "4  [bought, gift, 3yr, old, granddaughter, , , dr...   \n",
       "5  [big, bulky, , bungee, lid, awkward, , stick, ...   \n",
       "6  [love, nipples, make, easy, baby, drink, wonde...   \n",
       "7  [washed, dried, set, , instructed, , white, ma...   \n",
       "8  [ordered, 12, pack, fuzzi, bunz, one, size, di...   \n",
       "9  [loved, idea, autograph, teddy, bear, daughter...   \n",
       "\n",
       "                                               stems  \\\n",
       "0  [love, cubeit, , funbit, , , , , perfect, , es...   \n",
       "1  [m, , green, , , bag, perfect, hold, sandwich,...   \n",
       "2  [great, product, good, qualiti, , fit, easili,...   \n",
       "3  [leg, warmer, great, , fit, bit, roomi, 4, mon...   \n",
       "4  [bought, gift, 3yr, old, granddaught, , , dri,...   \n",
       "5  [big, bulki, , bunge, lid, awkward, , stick, t...   \n",
       "6  [love, nippl, make, easi, babi, drink, wonder,...   \n",
       "7  [wash, dri, set, , instruct, , white, materi, ...   \n",
       "8  [order, 12, pack, fuzzi, bunz, one, size, diap...   \n",
       "9  [love, idea, autograph, teddi, bear, daughter,...   \n",
       "\n",
       "                                              ngrams  \\\n",
       "0  [love cubeit , cubeit  funbit,  funbit , funbi...   \n",
       "1  [m  green,  green , green  ,   bag,  bag perfe...   \n",
       "2  [great product good, product good qualiti, goo...   \n",
       "3  [leg warmer great, warmer great , great  fit, ...   \n",
       "4  [bought gift 3yr, gift 3yr old, 3yr old grandd...   \n",
       "5  [big bulki , bulki  bunge,  bunge lid, bunge l...   \n",
       "6  [love nippl make, nippl make easi, make easi b...   \n",
       "7  [wash dri set, dri set , set  instruct,  instr...   \n",
       "8  [order 12 pack, 12 pack fuzzi, pack fuzzi bunz...   \n",
       "9  [love idea autograph, idea autograph teddi, au...   \n",
       "\n",
       "                                                  tf  \\\n",
       "0  (2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            features  \\\n",
       "0  (3.658600720360723, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (1.8293003601803615, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                               rawPrediction  \\\n",
       "0    [-158.8174727939285, 158.8174727939285]   \n",
       "1    [-62.64797630192351, 62.64797630192351]   \n",
       "2    [-92.92631076516145, 92.92631076516145]   \n",
       "3  [-48.550567254874686, 48.550567254874686]   \n",
       "4  [-105.00144560466066, 105.00144560466066]   \n",
       "5    [-4.325467740946893, 4.325467740946893]   \n",
       "6  [-31.811646690049752, 31.811646690049752]   \n",
       "7    [-41.08744355268045, 41.08744355268045]   \n",
       "8    [46.82453602221994, -46.82453602221994]   \n",
       "9  [-100.96032033879625, 100.96032033879625]   \n",
       "\n",
       "                                    probability  prediction  \n",
       "0                 [1.0627911657850075e-69, 1.0]         1.0  \n",
       "1                 [6.1991135245042445e-28, 1.0]         1.0  \n",
       "2                 [4.3915315891365726e-41, 1.0]         1.0  \n",
       "3                   [8.21781855294416e-22, 1.0]         1.0  \n",
       "4                   [2.50294658809125e-46, 1.0]         1.0  \n",
       "5     [0.01305468266162946, 0.9869453173383707]         1.0  \n",
       "6  [1.5288940209156156e-14, 0.9999999999999847]         1.0  \n",
       "7                 [1.4320229876135606e-18, 1.0]         1.0  \n",
       "8                 [1.0, 4.6170267192573065e-21]         0.0  \n",
       "9                 [1.4239344120021173e-44, 1.0]         1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.transform(test_data)\n",
    "\n",
    "pred.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "As in the original exercise, we want to use a custom metric for assessing the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import *\n",
    "\n",
    "class AccuracyClassificationEvaluator(Evaluator):\n",
    "    def __init__(self, predictionCol='prediction', labelCol='label'):\n",
    "        super(Evaluator,self).__init__()\n",
    "        self.predictionCol = predictionCol\n",
    "        self.labelCol = labelCol\n",
    "    \n",
    "    def _evaluate(self, dataset):\n",
    "        num_total = dataset.count()\n",
    "        num_correct = dataset.filter(col(self.labelCol) == col(self.predictionCol)).count()\n",
    "        accuracy = float(num_correct) / num_total\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Performance\n",
    "\n",
    "With the evaluator we can assess the performance of the prediction and easily compare it to a simple model which always predicts 'positive'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num positive reviews: 26774\n",
      "Num negative reviews: 4923\n"
     ]
    }
   ],
   "source": [
    "print(\"Num positive reviews: %d\" % pred.filter(pred.sentiment > 0.5).count())\n",
    "print(\"Num negative reviews: %d\" % pred.filter(pred.sentiment < 0.5).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 0.880777\n",
      "Baseline Accuracy = 0.844686\n"
     ]
    }
   ],
   "source": [
    "always_positive = pred.withColumn('prediction',lit(1.0))\n",
    "\n",
    "evaluator = AccuracyClassificationEvaluator(predictionCol='prediction', labelCol='sentiment')\n",
    "\n",
    "print(\"Model Accuracy = %f\" % evaluator.evaluate(pred))\n",
    "print(\"Baseline Accuracy = %f\" % evaluator.evaluate(always_positive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning\n",
    "\n",
    "The whole pipeline has some parameters which have an influence on the result, i.e. the accuracy. For example the size of the n-grams will probably have a big impact and also the minDF parameter of the CountVecttorizer will probably have some impact. These settings are called \"hyper parameters\", because they are also model parameters, but not learnt directly during the training phase. But which parameters work best?\n",
    "\n",
    "We will use a CrossValidation to select the best set of hyperparameters.\n",
    "\n",
    "First let us have a look at the paremeters of some stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputCol: input column name. (current: stems)\n",
      "n: number of elements per n-gram (>=1) (default: 2, current: 3)\n",
      "outputCol: output column name. (default: NGram_4eb7a55814a13390ec8a__output, current: ngrams)\n"
     ]
    }
   ],
   "source": [
    "print(pipe.getStages()[5].explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ParamGrid\n",
    "\n",
    "Now we create a param grid that should be used for using different sets of parameters. We want to tweak two parameters again:\n",
    "\n",
    "* regParam should take values in [0.0, 0.0001, 0.01, 1.0, 100.0]\n",
    "* maxIter should take values in [10, 100])\n",
    "\n",
    "In order to create this grid, we first need to create an instance of a LogisticRegression, so we can access its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import *\n",
    "\n",
    "ngram = pipe.getStages()[5]\n",
    "count = pipe.getStages()[6]\n",
    "\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(ngram.n, [2, 3, 5]) \\\n",
    "    .addGrid(count.minDF, [1, 2, 3, 5]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "\n",
    "Now we can create a pipeline using a CrossValidator instead of directly using a LogisticRegression. This means the configuration of the Pipeline should match the old one except that a CrossValidator is inserted instead of the LogisticRegression. The CrossValidator works as a wrapper of the regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = AccuracyClassificationEvaluator(labelCol='sentiment')\n",
    "validator = CrossValidator(estimator=pipe, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# Fit model to pipeline\n",
    "model = validator.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 0.909638\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'always_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c78fb9eeffc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model Accuracy = %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline Accuracy = %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'always_positive' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict sentiment for test data\n",
    "pred = model.transform(test_data)\n",
    "always_positive = pred.withColumn('prediction',lit(1.0))\n",
    "\n",
    "print(\"Model Accuracy = %f\" % evaluator.evaluate(pred))\n",
    "print(\"Baseline Accuracy = %f\" % evaluator.evaluate(always_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PySpark 2.1 (Python 3.5)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
