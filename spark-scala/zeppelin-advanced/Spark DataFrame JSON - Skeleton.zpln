{"paragraphs":[{"text":"%md\n# Working with JSON Data\n\nSpark supports reading and writing JSON very well out of the box. But the possible nesting of structures in JSONs often require some different approach in contrast when working with simple CSV files (or otherwise flat data models). Let us try to work a little bit with Twitter streaming data, which is proivded as complex nested JSON data.\n\n## 1. Load and Inspect\n\nFirst let's load some Twitter data and inspect its schema and some records","user":"anonymous","dateUpdated":"2019-04-04T16:57:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Working with JSON Data</h1>\n<p>Spark supports reading and writing JSON very well out of the box. But the possible nesting of structures in JSONs often require some different approach in contrast when working with simple CSV files (or otherwise flat data models). Let us try to work a little bit with Twitter streaming data, which is proivded as complex nested JSON data.</p>\n<h2>1. Load and Inspect</h2>\n<p>First let's load some Twitter data and inspect its schema and some records</p>\n"}]},"apps":[],"jobName":"paragraph_1554397020792_-915496125","id":"20180704-154213_1674119133","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:12316"},{"text":"val tweets = spark.read.json(\"s3://dimajix-training/data/twitter-sample/\")\n\ntweets.printSchema","user":"anonymous","dateUpdated":"2019-04-04T16:57:45+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397020797_-1131616240","id":"20180704-154407_392895719","dateCreated":"2019-04-04T16:57:00+0000","dateStarted":"2019-04-04T16:57:46+0000","dateFinished":"2019-04-04T16:59:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12317","errorMessage":""},{"text":"tweets.limit(10).show()","user":"anonymous","dateUpdated":"2019-04-04T16:57:00+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397020798_-783517025","id":"20180704-154500_1952221229","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12318"},{"text":"%md\n### Challanges for working with the data\n\nThe highly nested and big structure of the JSON makes working with the data hard. Especially we have to cope with:\n* Nested structures\n* Arrays\n* Arrays of Arrays\n\nLet's address one item after another.","user":"anonymous","dateUpdated":"2019-04-04T16:57:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Challanges for working with the data</h3>\n<p>The highly nested and big structure of the JSON makes working with the data hard. Especially we have to cope with:</p>\n<ul>\n<li>Nested structures</li>\n<li>Arrays</li>\n<li>Arrays of Arrays</li>\n</ul>\n<p>Let's address one item after another.</p>\n"}]},"apps":[],"jobName":"paragraph_1554397020799_-1442232348","id":"20180704-154519_1668113985","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12319"},{"text":"%md\n## 2. Addressing Nested Structures\n\nSo the first question that arises is how to address nested data. This is fairly simple, the JSON path can be specified using a dot notation:\n","user":"anonymous","dateUpdated":"2019-04-04T16:57:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>2. Addressing Nested Structures</h2>\n<p>So the first question that arises is how to address nested data. This is fairly simple, the JSON path can be specified using a dot notation:</p>\n"}]},"apps":[],"jobName":"paragraph_1554397020799_-1581361117","id":"20180704-154714_850759450","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12320"},{"text":"val result = // YOUR CODE HERE\n\nz.show(result.limit(10))\n","user":"anonymous","dateUpdated":"2019-04-04T17:46:39+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{"1":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"created_at":"string","country_code":"string","display_url":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397020799_1926181284","id":"20180704-154814_1118470462","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12321"},{"text":"result.printSchema()","user":"anonymous","dateUpdated":"2019-04-04T16:57:00+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397020800_-351515614","id":"20180704-160226_1706207431","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12322"},{"text":"%md\n## 3. Unpacking Structs\n\nSometimes you want to lift a couple of nested elements to the top. This can be done fairly easily as follows","user":"anonymous","dateUpdated":"2019-04-04T16:57:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>3. Unpacking Structs</h2>\n<p>Sometimes you want to lift a couple of nested elements to the top. This can be done fairly easily as follows</p>\n"}]},"apps":[],"jobName":"paragraph_1554397020800_39229209","id":"20180704-155755_976729331","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12323"},{"text":"val result = // YOUR CODE HERE\n\nz.show(result.limit(10))","user":"anonymous","dateUpdated":"2019-04-04T17:47:12+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{"1":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"created_at":"string","bounding_box":"string","country":"string","country_code":"string","full_name":"string","id":"string","name":"string","place_type":"string","url":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397020801_-118363737","id":"20180704-155839_600489148","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12324"},{"text":"result.printSchema()","user":"anonymous","dateUpdated":"2019-04-04T16:57:00+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397020801_753314787","id":"20180704-160244_310247267","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12325"},{"text":"%md\n## 4. Unpacking Arrays\n\nOften it is desirable to unpack an array, i.e. create separate records for all entries in an array. This can be done with the `explode` or `explode_outer` function.","user":"anonymous","dateUpdated":"2019-04-04T16:57:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>4. Unpacking Arrays</h2>\n<p>Often it is desirable to unpack an array, i.e. create separate records for all entries in an array. This can be done with the <code>explode</code> or <code>explode_outer</code> function.</p>\n"}]},"apps":[],"jobName":"paragraph_1554397020802_1860930449","id":"20180704-154951_1932672658","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12326"},{"text":"val result = // YOUR CODE HERE\n\nz.show(result.limit(10))\n","user":"anonymous","dateUpdated":"2019-04-04T17:47:31+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{"1":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"created_at":"string","media":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397020802_-1289663520","id":"20180704-155524_316915102","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12327"},{"text":"result.printSchema()","user":"anonymous","dateUpdated":"2019-04-04T16:57:00+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397020802_1652389684","id":"20180704-155541_1582297499","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12328"},{"text":"%md\n# 5. Collection Functions\n\nSpark 2.4 extended the support for arrays and maps by implementing many new SQL functions. Specifically so called *higher order functions* have been introduced which work similar to Spark/Scala `map`, `filter` and relaqted functions. Unfortunately many of these functions are not available in the Scala API, so we have to use SQL.\n\nLet us have a look at some examples how these new functions can help us while working with the tweets.","user":"anonymous","dateUpdated":"2019-04-04T17:27:54+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>5. Collection Functions</h1>\n<p>Spark 2.4 extended the support for arrays and maps by implementing many new SQL functions. Specifically so called <em>higher order functions</em> have been introduced which work similar to Spark/Scala <code>map</code>, <code>filter</code> and relaqted functions. Unfortunately many of these functions are not available in the Scala API, so we have to use SQL.</p>\n<p>Let us have a look at some examples how these new functions can help us while working with the tweets.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554397039718_-1993895475","id":"20190404-165719_1571662602","dateCreated":"2019-04-04T16:57:19+0000","dateStarted":"2019-04-04T17:27:54+0000","dateFinished":"2019-04-04T17:27:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12329"},{"text":"tweets.cache()\ntweets.createOrReplaceTempView(\"tweets\")","user":"anonymous","dateUpdated":"2019-04-04T17:05:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res8: tweets.type = [contributors: string, coordinates: struct<coordinates: array<double>, type: string> ... 31 more fields]\n"}]},"apps":[],"jobName":"paragraph_1554397165565_487250925","id":"20190404-165925_95820515","dateCreated":"2019-04-04T16:59:25+0000","dateStarted":"2019-04-04T17:05:50+0000","dateFinished":"2019-04-04T17:05:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12330"},{"text":"%md\n### Find tweets containing a specific hashtag with `array_contains`\n\nIn the first example, we are interested in all tweets that contain a specific hashtag. Hashtags are provided in the nested entity `entities.hashtags.text`, but this will be an array. Thanks to the new functions, we can easily check if that array contains a specific word.","user":"anonymous","dateUpdated":"2019-04-04T17:31:01+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Find tweets containing a specific hashtag with <code>array_contains</code></h3>\n<p>In the first example, we are interested in all tweets that contain a specific hashtag. Hashtags are provided in the nested entity <code>entities.hashtags.text</code>, but this will be an array. Thanks to the new functions, we can easily check if that array contains a specific word.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554398311041_974987165","id":"20190404-171831_87235992","dateCreated":"2019-04-04T17:18:31+0000","dateStarted":"2019-04-04T17:31:01+0000","dateFinished":"2019-04-04T17:31:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12331"},{"text":"%sql\nSELECT\n    entities.hashtags.text\nFROM tweets\n-- YOUR CODE HERE\nLIMIT 5","user":"anonymous","dateUpdated":"2019-04-04T17:48:21+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"text":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554398278238_-1451457033","id":"20190404-171758_1745979585","dateCreated":"2019-04-04T17:17:58+0000","dateStarted":"2019-04-04T17:48:03+0000","dateFinished":"2019-04-04T17:48:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12332","errorMessage":""},{"text":"%md\n### Find tweets with long hashtags using `exists`\n\nNow let us try a more generic filter, where we want to inspect all tweets that contain at least one long hashtag with at least 20 characters. This can be achieved by using the higher order function `exists` which works similar to the Scala collection method `exists`. This method is much more flexible than `array_contains` since we do not need to speify a specifc word, but we can define an arbitrary predicate that is being checked.","user":"anonymous","dateUpdated":"2019-04-04T17:31:53+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Find tweets with long hashtags using <code>exists</code></h3>\n<p>Now let us try a more generic filter, where we want to inspect all tweets that contain at least one long hashtag with at least 20 characters. This can be achieved by using the higher order function <code>exists</code> which works similar to the Scala collection method <code>exists</code>. This method is much more flexible than <code>array_contains</code> since we do not need to speify a specifc word, but we can define an arbitrary predicate that is being checked.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554397571874_338461100","id":"20190404-170611_1116435093","dateCreated":"2019-04-04T17:06:11+0000","dateStarted":"2019-04-04T17:31:53+0000","dateFinished":"2019-04-04T17:31:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12333"},{"text":"%sql\nSELECT\n    entities.hashtags.text\nFROM tweets\n-- YOUR CODE HERE\nLIMIT 5","user":"anonymous","dateUpdated":"2019-04-04T17:48:35+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"text":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397058700_1593034774","id":"20190404-165738_1867224896","dateCreated":"2019-04-04T16:57:38+0000","dateStarted":"2019-04-04T17:17:26+0000","dateFinished":"2019-04-04T17:17:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12334","errorMessage":""},{"text":"%md\n### Keep only long hashtags using `filter`\n\nWhile `exists` only checks if an array contains an entry with some specific condition, the function `filter` allows us to remove all non-conforming entries from an array. This works very similar to the Scala method `filter`.","user":"anonymous","dateUpdated":"2019-04-04T17:33:23+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Keep only long hashtags using <code>filter</code></h3>\n<p>While <code>exists</code> only checks if an array contains an entry with some specific condition, the function <code>filter</code> allows us to remove all non-conforming entries from an array. This works very similar to the Scala method <code>filter</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554398589204_1069807205","id":"20190404-172309_1344591137","dateCreated":"2019-04-04T17:23:09+0000","dateStarted":"2019-04-04T17:33:23+0000","dateFinished":"2019-04-04T17:33:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12335"},{"text":"%sql\nSELECT\n    -- YOUR CODE HERE\nFROM tweets\nWHERE exists(entities.hashtags, x -> length(x.text) > 20)\nLIMIT 5","user":"anonymous","dateUpdated":"2019-04-04T17:53:44+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"filter(entities.hashtags.text AS `text`, lambdafunction((length(namedlambdavariable()) > 20), namedlambdavariable()))":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554398586375_-1329707617","id":"20190404-172306_655718289","dateCreated":"2019-04-04T17:23:06+0000","dateStarted":"2019-04-04T17:24:48+0000","dateFinished":"2019-04-04T17:24:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12336","errorMessage":""},{"text":"%md\n### Convert case of Hashtags using `transform`\n\nWe can use the function `transform` to specify a transformation that should be applied to every entry in an array. That means that `transform` works very similar to the Scala method `map` which also performs an element-wise transformation of a sequence.","user":"anonymous","dateUpdated":"2019-04-04T17:34:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Convert case of Hashtags using <code>transform</code></h3>\n<p>We can use the function <code>transform</code> to specify a transformation that should be applied to every entry in an array. That means that <code>transform</code> works very similar to the Scala method <code>map</code> which also performs an element-wise transformation of a sequence.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554398051168_-209931800","id":"20190404-171411_896041674","dateCreated":"2019-04-04T17:14:11+0000","dateStarted":"2019-04-04T17:34:50+0000","dateFinished":"2019-04-04T17:34:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12337"},{"text":"%sql\nSELECT\n    -- YOUR CODE HERE\nFROM tweets\nWHERE entities.hashtags.text[0] IS NOT NULL\nLIMIT 20","user":"anonymous","dateUpdated":"2019-04-04T17:49:22+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"transform(entities.hashtags.text AS `text`, lambdafunction(upper(namedlambdavariable()), namedlambdavariable()))":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554398072374_1563406113","id":"20190404-171432_2126846431","dateCreated":"2019-04-04T17:14:32+0000","dateStarted":"2019-04-04T17:15:28+0000","dateFinished":"2019-04-04T17:15:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12338","errorMessage":""},{"text":"%md\n### Find longest hashtag using `aggregate`\n\nFinally Spark also provides an `aggregate` method for reducing an array to a single element. This works very similar to the Scala `foldLeft` method with an aggregation state (or accumulator) and a function which updates the accumulator. In this example we select the longest hashtag inside the array by a simple aggregation. The accumulator will contain the longest hashtag seen so far and will be updated once a longer hashtag is found.","user":"anonymous","dateUpdated":"2019-04-04T17:36:48+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Find longest hashtag using <code>aggregate</code></h3>\n<p>Finally Spark also provides an <code>aggregate</code> method for reducing an array to a single element. This works very similar to the Scala <code>foldLeft</code> method with an aggregation state (or accumulator) and a function which updates the accumulator. In this example we select the longest hashtag inside the array by a simple aggregation. The accumulator will contain the longest hashtag seen so far and will be updated once a longer hashtag is found.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554397658340_1977197907","id":"20190404-170738_380935028","dateCreated":"2019-04-04T17:07:38+0000","dateStarted":"2019-04-04T17:36:48+0000","dateFinished":"2019-04-04T17:36:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12339"},{"text":"%sql\nSELECT\n    -- YOUR CODE HERE\nFROM tweets\nWHERE exists(entities.hashtags, x -> x IS NOT NULL)\nLIMIT 5","user":"anonymous","dateUpdated":"2019-04-04T17:54:30+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"longest_hashtag":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"longest_hashtag\nالسعودية\nValentinaZenereVillana\nsecurity\nGeneralstaatsanwaltschaft\nUnprettyRapstar3\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-10-200-101-39.eu-central-1.compute.internal:4040/jobs/job?id=9"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554397600295_-155506452","id":"20190404-170640_1017816523","dateCreated":"2019-04-04T17:06:40+0000","dateStarted":"2019-04-04T17:09:43+0000","dateFinished":"2019-04-04T17:09:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12340"},{"text":"%md\n# 5. Working with Hive\n\nSupport for nested data is not only provided by Spark, but Hive also supports that to a certain extend. This is also required since some important file formats like Parquet, ORC, JSON and Avro all support nested data.\n\nAlthough Hive was originally meant to be in line with a classical data warehouse containing (possibly wide but) flat tables, support for nested structures have been added. This is true both for the Hive meta store which only stores the structural information and file location and also for the Hive execution engine, although the later is lacking behind as compared to Spark. Different execution engines like Impala, Drill, Presto etc will also specific levels of support for nested data. Presto for example offers a very good support, which actually was used as a template by the Spark developers for their functionality introduced with Spark 2.4.","user":"anonymous","dateUpdated":"2019-04-04T17:42:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>5. Working with Hive</h1>\n<p>Support for nested data is not only provided by Spark, but Hive also supports that to a certain extend. This is also required since some important file formats like Parquet, ORC, JSON and Avro all support nested data.</p>\n<p>Although Hive was originally meant to be in line with a classical data warehouse containing (possibly wide but) flat tables, support for nested structures have been added. This is true both for the Hive meta store which only stores the structural information and file location and also for the Hive execution engine, although the later is lacking behind as compared to Spark. Different execution engines like Impala, Drill, Presto etc will also specific levels of support for nested data. Presto for example offers a very good support, which actually was used as a template by the Spark developers for their functionality introduced with Spark 2.4.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554397020803_-877381043","id":"20180704-160301_1039604398","dateCreated":"2019-04-04T16:57:00+0000","dateStarted":"2019-04-04T17:42:59+0000","dateFinished":"2019-04-04T17:42:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12341"},{"text":"%md\n### Write Tweets to Hive Table","user":"anonymous","dateUpdated":"2019-04-04T17:44:36+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Write Tweets to Hive Table</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1554399804923_-1462751770","id":"20190404-174324_747902637","dateCreated":"2019-04-04T17:43:24+0000","dateStarted":"2019-04-04T17:43:36+0000","dateFinished":"2019-04-04T17:43:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12342"},{"text":"tweets.write.format(\"parquet\").saveAsTable(\"tweets\")","user":"anonymous","dateUpdated":"2019-04-04T17:43:23+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-10-200-101-39.eu-central-1.compute.internal:4040/jobs/job?id=23"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554397020803_-418157599","id":"20190404-152940_141176272","dateCreated":"2019-04-04T16:57:00+0000","dateStarted":"2019-04-04T17:43:23+0000","dateFinished":"2019-04-04T17:43:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12343"},{"text":"%md\n### Inspect Schema","user":"anonymous","dateUpdated":"2019-04-04T17:44:38+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Inspect Schema</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1554399789682_543236103","id":"20190404-174309_95705262","dateCreated":"2019-04-04T17:43:09+0000","dateStarted":"2019-04-04T17:43:20+0000","dateFinished":"2019-04-04T17:43:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12344"},{"text":"%sql\n-- YOUR CODE HERE","user":"anonymous","dateUpdated":"2019-04-04T17:54:55+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"col_name":"string","data_type":"string","comment":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397020804_-154032005","id":"20190404-153006_1759726621","dateCreated":"2019-04-04T16:57:00+0000","dateStarted":"2019-04-04T17:44:09+0000","dateFinished":"2019-04-04T17:44:09+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12345","errorMessage":""},{"text":"%sql\n-- YOUR CODE HERE","user":"anonymous","dateUpdated":"2019-04-04T17:55:05+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"entities.media AS `media`[0].display_url":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397020804_1987966927","id":"20190404-153128_1909420138","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12346"},{"text":"%sql\n","user":"anonymous","dateUpdated":"2019-04-04T16:57:00+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554397020805_-1171248037","id":"20190404-153642_1766653186","dateCreated":"2019-04-04T16:57:00+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:12347"}],"name":"Spark DataFrame JSON - Skeleton","id":"2E87NMNKN","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}