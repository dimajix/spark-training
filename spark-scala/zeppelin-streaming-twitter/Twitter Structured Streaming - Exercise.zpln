{
  "paragraphs": [
    {
      "text": "%md\n# 0. Add Dependencies\n\nBefore we start working with Spark and Kafka, we need to add the Spark Kafka SQL dependency to Zeppelin:\n```\norg.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1 exclude: net.jpountz.lz4:lz4\nmysql:mysql-connector-java:6.0.6\n```",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:54:06+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "editorHide": true,
        "results": {},
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h1>0. Add Dependencies</h1>\n<p>Before we start working with Spark and Kafka, we need to add the Spark Kafka SQL dependency to Zeppelin:</p>\n<pre><code>org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1 exclude: net.jpountz.lz4:lz4\nmysql:mysql-connector-java:6.0.6\n</code></pre>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512045_-1798059205",
      "id": "20180605-073622_654118248",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "dateStarted": "2021-09-18T06:54:03+0000",
      "dateFinished": "2021-09-18T06:54:03+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:11410"
    },
    {
      "text": "%md\n# 1. Connect to data source\n\nFirst you need to fill a Kafka topic, for example via\n\n    s3cat.py -I1 -B10 s3://dimajix-training/data/twitter-sample/ | /opt/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic twitter\n\nThen we connect to the raw data socket as the datasource by using the `DataStreamReader` API via `spark.readStream`. We need to specify the options `kafka.bootstrap.servers` and `subscribe` and we need to use the format `kafka` for connecting to the data source. The Kafka topic will stream Twitter data samples in raw JSON format, i.e. one JSON document per line.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h1>1. Connect to data source</h1>\n<p>First you need to fill a Kafka topic, for example via</p>\n<pre><code>s3cat.py -I1 -B10 s3://dimajix-training/data/twitter-sample/ | /opt/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic twitter\n</code></pre>\n<p>Then we connect to the raw data socket as the datasource by using the <code>DataStreamReader</code> API via <code>spark.readStream</code>. We need to specify the options <code>kafka.bootstrap.servers</code> and <code>subscribe</code> and we need to use the format <code>kafka</code> for connecting to the data source. The Kafka topic will stream Twitter data samples in raw JSON format, i.e. one JSON document per line.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512046_29165769",
      "id": "20170218-160028_195174762",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11411"
    },
    {
      "text": "// Fill in the correct AWS VPC address of your master host\nval master = ...\n\n// Connect to raw text stream socket using the DataStreamReader API via spark.readStream. You need to specify the options `host`, `port` and you need to use the format `socket`\nval lines = spark.readStream\n  .format(\"kafka\")\n  .option(\"kafka.bootstrap.servers\", master + \":9092\")\n  .option(\"subscribe\", \"twitter\")\n  .option(\"startingOffsets\", \"earliest\")\n  .load()",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512046_1728442617",
      "id": "20170218-160002_129671727",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11412"
    },
    {
      "text": "%md\n## 1.1 Inspect Schema\n\nThe result of the load method is a `DataFrame` again, but a streaming one. This `DataFrame` again has a schema, which we can inspect with the usual method:",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "colWidth": 12,
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {},
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h2>1.1 Inspect Schema</h2>\n<p>The result of the load method is a <code>DataFrame</code> again, but a streaming one. This <code>DataFrame</code> again has a schema, which we can inspect with the usual method:</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512046_1851322012",
      "id": "20170218-161504_128762750",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11413"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512046_153508843",
      "id": "20170218-160206_920542952",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11414"
    },
    {
      "text": "%md\n# 2. Inspect Data\n\nOf course we also want to inspect the data inside the DataFrame. But this time, we cannot simply invoke `show`, because normal actions do not (directly) work on streaming DataFrames. Instead we need to create a continiuous query. Later, we will see a neat trick how a streaming query can be transformed into a volatile table.\n\nIn order to create a continuous query, we need to perform the following steps\n\n1. Create a `DataStreamWriter` by using the `writeStream` method of a DataFrame\n2. Specify the output format. We use `console` in our case\n3. Specify a checkpoint location on HDFS. This is required for restarting\n4. Optionally specify a processing period\n5. Start the query\n6. For Zeppelin only: Sleep a little bit, or we miss the output",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h1>2. Inspect Data</h1>\n<p>Of course we also want to inspect the data inside the DataFrame. But this time, we cannot simply invoke <code>show</code>, because normal actions do not (directly) work on streaming DataFrames. Instead we need to create a continiuous query. Later, we will see a neat trick how a streaming query can be transformed into a volatile table.</p>\n<p>In order to create a continuous query, we need to perform the following steps</p>\n<ol>\n<li>Create a <code>DataStreamWriter</code> by using the <code>writeStream</code> method of a DataFrame</li>\n<li>Specify the output format. We use <code>console</code> in our case</li>\n<li>Specify a checkpoint location on HDFS. This is required for restarting</li>\n<li>Optionally specify a processing period</li>\n<li>Start the query</li>\n<li>For Zeppelin only: Sleep a little bit, or we miss the output</li>\n</ol>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512046_-711921600",
      "id": "20170218-161603_528321172",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11415"
    },
    {
      "text": "import org.apache.spark.sql.streaming.ProcessingTime\n\nval query = ...",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512046_1392303293",
      "id": "20170218-160132_1015574950",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11416"
    },
    {
      "text": "%md\n## 2.1 Stop Query\n\nIn contrast to the RDD API, we can simply stop an individual query instead of a whole StreamingContext by simply calling the `stop` method on the query object. This makes working with streams much easier.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {},
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h2>2.1 Stop Query</h2>\n<p>In contrast to the RDD API, we can simply stop an individual query instead of a whole StreamingContext by simply calling the <code>stop</code> method on the query object. This makes working with streams much easier.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512046_-1684028092",
      "id": "20170218-161746_736484246",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11417"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": [],
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512046_-2029342064",
      "id": "20170218-160155_661067655",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11418"
    },
    {
      "text": "%md\n# 3. Counting Hash-Tags\n\nSo we now want to create a streaming hashtag count. First we need to extract the Tweet itself from the JSON document, then we need to extract the hashtags in a similar way to the batch word traditional DataFrame word count example, i.e. we split every line into words, keep only hash-tags, group the words and count the sizes of the groups.\n\nEach query looks as follows\n\n```\n{ \"contributors\" : null,\n  \"coordinates\" : null,\n  \"created_at\" : \"Fri Jul 29 12:46:00 +0000 2016\",\n  \"entities\" : { \"hashtags\" : [  ],\n      \"symbols\" : [  ],\n      \"urls\" : [ { \"display_url\" : \"fb.me/ItnwZEhy\",\n            \"expanded_url\" : \"http://fb.me/ItnwZEhy\",\n            \"indices\" : [ 33,\n                56\n              ],\n            \"url\" : \"https://t.co/mM0if95F1K\"\n          } ],\n      \"user_mentions\" : [  ]\n    },\n  \"favorite_count\" : 0,\n  \"favorited\" : false,\n  \"filter_level\" : \"low\",\n  \"geo\" : null,\n  \"id\" : 759007065155117058,\n  \"id_str\" : \"759007065155117058\",\n  \"in_reply_to_screen_name\" : null,\n  \"in_reply_to_status_id\" : null,\n  \"in_reply_to_status_id_str\" : null,\n  \"in_reply_to_user_id\" : null,\n  \"in_reply_to_user_id_str\" : null,\n  \"is_quote_status\" : false,\n  \"lang\" : \"en\",\n  \"place\" : null,\n  \"possibly_sensitive\" : false,\n  \"retweet_count\" : 0,\n  \"retweeted\" : false,\n  \"source\" : \"<a href=\\\"http://www.facebook.com/twitter\\\" rel=\\\"nofollow\\\">Facebook</a>\",\n  \"text\" : \"I posted a new video to Facebook https://t.co/mM0if95F1K\",\n  \"timestamp_ms\" : \"1469796360659\",\n  \"truncated\" : false,\n  \"user\" : { \"contributors_enabled\" : false,\n      \"created_at\" : \"Sat Sep 08 08:28:55 +0000 2012\",\n      \"default_profile\" : false,\n      \"default_profile_image\" : false,\n      \"description\" : null,\n      \"favourites_count\" : 0,\n      \"follow_request_sent\" : null,\n      \"followers_count\" : 0,\n      \"following\" : null,\n      \"friends_count\" : 0,\n      \"geo_enabled\" : false,\n      \"id\" : 810489374,\n      \"id_str\" : \"810489374\",\n      \"is_translator\" : false,\n      \"lang\" : \"zh-tw\",\n      \"listed_count\" : 0,\n      \"location\" : null,\n      \"name\" : \"張冥閻\",\n      \"notifications\" : null,\n      \"profile_background_color\" : \"FFF04D\",\n      \"profile_background_image_url\" : \"http://abs.twimg.com/images/themes/theme19/bg.gif\",\n      \"profile_background_image_url_https\" : \"https://abs.twimg.com/images/themes/theme19/bg.gif\",\n      \"profile_background_tile\" : false,\n      \"profile_image_url\" : \"http://pbs.twimg.com/profile_images/378800000157469481/0a267258c8ccd1bf53d01c115677dbd7_normal.jpeg\",\n      \"profile_image_url_https\" : \"https://pbs.twimg.com/profile_images/378800000157469481/0a267258c8ccd1bf53d01c115677dbd7_normal.jpeg\",\n      \"profile_link_color\" : \"0099CC\",\n      \"profile_sidebar_border_color\" : \"FFF8AD\",\n      \"profile_sidebar_fill_color\" : \"F6FFD1\",\n      \"profile_text_color\" : \"333333\",\n      \"profile_use_background_image\" : true,\n      \"protected\" : false,\n      \"screen_name\" : \"nineemperor1\",\n      \"statuses_count\" : 9652,\n      \"time_zone\" : null,\n      \"url\" : null,\n      \"utc_offset\" : null,\n      \"verified\" : false\n    }\n}\n```\n\nIn order to extract a field from a JSON document, we can use the `get_json_object` function.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {},
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h1>3. Counting Hash-Tags</h1>\n<p>So we now want to create a streaming hashtag count. First we need to extract the Tweet itself from the JSON document, then we need to extract the hashtags in a similar way to the batch word traditional DataFrame word count example, i.e. we split every line into words, keep only hash-tags, group the words and count the sizes of the groups.</p>\n<p>Each query looks as follows</p>\n<pre><code>{ \"contributors\" : null,\n  \"coordinates\" : null,\n  \"created_at\" : \"Fri Jul 29 12:46:00 +0000 2016\",\n  \"entities\" : { \"hashtags\" : [  ],\n      \"symbols\" : [  ],\n      \"urls\" : [ { \"display_url\" : \"fb.me/ItnwZEhy\",\n            \"expanded_url\" : \"http://fb.me/ItnwZEhy\",\n            \"indices\" : [ 33,\n                56\n              ],\n            \"url\" : \"https://t.co/mM0if95F1K\"\n          } ],\n      \"user_mentions\" : [  ]\n    },\n  \"favorite_count\" : 0,\n  \"favorited\" : false,\n  \"filter_level\" : \"low\",\n  \"geo\" : null,\n  \"id\" : 759007065155117058,\n  \"id_str\" : \"759007065155117058\",\n  \"in_reply_to_screen_name\" : null,\n  \"in_reply_to_status_id\" : null,\n  \"in_reply_to_status_id_str\" : null,\n  \"in_reply_to_user_id\" : null,\n  \"in_reply_to_user_id_str\" : null,\n  \"is_quote_status\" : false,\n  \"lang\" : \"en\",\n  \"place\" : null,\n  \"possibly_sensitive\" : false,\n  \"retweet_count\" : 0,\n  \"retweeted\" : false,\n  \"source\" : \"&lt;a href=\\\"http://www.facebook.com/twitter\\\" rel=\\\"nofollow\\\"&gt;Facebook&lt;/a&gt;\",\n  \"text\" : \"I posted a new video to Facebook https://t.co/mM0if95F1K\",\n  \"timestamp_ms\" : \"1469796360659\",\n  \"truncated\" : false,\n  \"user\" : { \"contributors_enabled\" : false,\n      \"created_at\" : \"Sat Sep 08 08:28:55 +0000 2012\",\n      \"default_profile\" : false,\n      \"default_profile_image\" : false,\n      \"description\" : null,\n      \"favourites_count\" : 0,\n      \"follow_request_sent\" : null,\n      \"followers_count\" : 0,\n      \"following\" : null,\n      \"friends_count\" : 0,\n      \"geo_enabled\" : false,\n      \"id\" : 810489374,\n      \"id_str\" : \"810489374\",\n      \"is_translator\" : false,\n      \"lang\" : \"zh-tw\",\n      \"listed_count\" : 0,\n      \"location\" : null,\n      \"name\" : \"張冥閻\",\n      \"notifications\" : null,\n      \"profile_background_color\" : \"FFF04D\",\n      \"profile_background_image_url\" : \"http://abs.twimg.com/images/themes/theme19/bg.gif\",\n      \"profile_background_image_url_https\" : \"https://abs.twimg.com/images/themes/theme19/bg.gif\",\n      \"profile_background_tile\" : false,\n      \"profile_image_url\" : \"http://pbs.twimg.com/profile_images/378800000157469481/0a267258c8ccd1bf53d01c115677dbd7_normal.jpeg\",\n      \"profile_image_url_https\" : \"https://pbs.twimg.com/profile_images/378800000157469481/0a267258c8ccd1bf53d01c115677dbd7_normal.jpeg\",\n      \"profile_link_color\" : \"0099CC\",\n      \"profile_sidebar_border_color\" : \"FFF8AD\",\n      \"profile_sidebar_fill_color\" : \"F6FFD1\",\n      \"profile_text_color\" : \"333333\",\n      \"profile_use_background_image\" : true,\n      \"protected\" : false,\n      \"screen_name\" : \"nineemperor1\",\n      \"statuses_count\" : 9652,\n      \"time_zone\" : null,\n      \"url\" : null,\n      \"utc_offset\" : null,\n      \"verified\" : false\n    }\n}\n</code></pre>\n<p>In order to extract a field from a JSON document, we can use the <code>get_json_object</code> function.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512046_1995540840",
      "id": "20170218-161837_1521722724",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11419"
    },
    {
      "text": "%md\n## 3.1 Extract Tweet\n\nFirst we need to extract the tweet text itself via the `get_json_object` function and store it into a new column.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {},
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h2>3.1 Extract Tweet</h2>\n<p>First we need to extract the tweet text itself via the <code>get_json_object</code> function and store it into a new column.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512046_-1543889213",
      "id": "20170220-182415_1872492795",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11420"
    },
    {
      "text": "import org.apache.spark.sql.types._\n\nval ts_text = lines.select(\n        (get_json_object($\"value\".cast(\"string\"), \"$.timestamp_ms\").cast(LongType) / lit(1000)).cast(TimestampType).as(\"ts\"),\n        get_json_object($\"value\".cast(\"string\"), \"$.text\").as(\"text\")\n    )",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_-1979313330",
      "id": "20170218-160238_1475524112",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11421"
    },
    {
      "text": "%md\n## 3.2 Extract Topics\n\nNow that we have the Tweet text itself, we extract all topics with the following approach:\n1. Split text along spaces using `split`\n2. Create multiple records from all words using `explode`\n3. Filter all hash-tags (words that start with a `#`)\n4. Filter out all empty topics (topic name only consists of hash-tag `#` itself)",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>3.2 Extract Topics</h2>\n<p>Now that we have the Tweet text itself, we extract all topics with the following approach:<br/>1. Split text along spaces using <code>split</code><br/>2. Create multiple records from all words using <code>explode</code><br/>3. Filter all hash-tags (words that start with a <code>#</code>)<br/>4. Filter out all empty topics (topic name only consists of hash-tag <code>#</code> itself)</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_316855968",
      "id": "20170220-182404_1394954195",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11422"
    },
    {
      "text": "val topics = ...",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_-882767811",
      "id": "20170220-180159_930749179",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11423"
    },
    {
      "text": "%md\n## 3.3 Count Topics\n\nNow that we have the hash tags (topics), we perform a simple aggregation as usual: Group by hashtag (`topic`) and count number of tweets (using `count` or `sum(1)`)",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>3.3 Count Topics</h2>\n<p>Now that we have the hash tags (topics), we perform a simple aggregation as usual: Group by hashtag (<code>topic</code>) and count number of tweets (using <code>count</code> or <code>sum(1)</code>)</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_-120682835",
      "id": "20170220-182554_1623876741",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11424"
    },
    {
      "text": "val counts = ...",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_-1987782142",
      "id": "20170218-160526_2008806660",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11425"
    },
    {
      "text": "counts.printSchema",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_-174711422",
      "id": "20170218-162308_1835168589",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11426"
    },
    {
      "text": "%md\n## 3.4 Print Results onto Console\n\nAgain we want to print the results onto the console.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h2>3.4 Print Results onto Console</h2>\n<p>Again we want to print the results onto the console.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_1865742475",
      "id": "20170218-161041_735302634",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11427"
    },
    {
      "text": "val query = ...",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_-367371082",
      "id": "20170218-160613_988660270",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11428"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": [],
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_572541861",
      "id": "20170218-160716_194527039",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11429"
    },
    {
      "text": "%md\n# 4. Time-Windowed Aggregation\n\nAnother interesting (and probably more realistic) application is to perform time windowed aggregations. This means that we define a sliding time window used in the `groupBy` clause. In addition we also define a so called *watermark* which tells Spark how long to wait for late arrivels of individual data points (we don't have them in our simple example).",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h1>4. Time-Windowed Aggregation</h1>\n<p>Another interesting (and probably more realistic) application is to perform time windowed aggregations. This means that we define a sliding time window used in the <code>groupBy</code> clause. In addition we also define a so called <em>watermark</em> which tells Spark how long to wait for late arrivels of individual data points (we don't have them in our simple example).</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_381064350",
      "id": "20170218-164639_1471935006",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11430"
    },
    {
      "text": "val windowedCounts = ...",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_-1746066951",
      "id": "20170218-164703_2039341008",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11431"
    },
    {
      "text": "windowedCounts.printSchema()",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_-147159140",
      "id": "20170218-165357_1483843188",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11432"
    },
    {
      "text": "%md\n## 4.1 Output Data\n\nLet's again output the data. This time, we also like to investigate the different output modes `append`, `complete` and `update`.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h2>4.1 Output Data</h2>\n<p>Let's again output the data. This time, we also like to investigate the different output modes <code>append</code>, <code>complete</code> and <code>update</code>.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512047_-1939591956",
      "id": "20180405-191252_609666009",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11433"
    },
    {
      "text": "val query = ...    \n    \nThread.sleep(60000)\n\nquery.stop()",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512048_-956890414",
      "id": "20180405-191259_700837965",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11434"
    },
    {
      "text": "%md\n## 4.2 Create Dynamic Table\n\nWe can also use a \"memory\" output, which is a queryable live table. In order to do so, we again create a new table, but this time with format `memory` and an explicit query name `topic_counts`. Using a `memory` output will create a dynamic table in memory (only `complete` output supported right now), which can be queried using SQL.\n\n1. Create a DataStreamWriter object using the writeStream method of your DataFrame `windowedCounts`.\n2. Set the format to `memory`\n3. Set the output mode to `append` (this is supported for time windowed aggregations)\n4. Set the query name to `topic_counts`\n5. Specify a checkPointLocation on HDFS (ok, this is not trivial, so it is in the code below)\n6. Start the continuous query via `start`",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h2>4.2 Create Dynamic Table</h2>\n<p>We can also use a &ldquo;memory&rdquo; output, which is a queryable live table. In order to do so, we again create a new table, but this time with format <code>memory</code> and an explicit query name <code>topic_counts</code>. Using a <code>memory</code> output will create a dynamic table in memory (only <code>complete</code> output supported right now), which can be queried using SQL.</p>\n<ol>\n<li>Create a DataStreamWriter object using the writeStream method of your DataFrame <code>windowedCounts</code>.</li>\n<li>Set the format to <code>memory</code></li>\n<li>Set the output mode to <code>append</code> (this is supported for time windowed aggregations)</li>\n<li>Set the query name to <code>topic_counts</code></li>\n<li>Specify a checkPointLocation on HDFS (ok, this is not trivial, so it is in the code below)</li>\n<li>Start the continuous query via <code>start</code></li>\n</ol>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512048_-1782213629",
      "id": "20170218-160934_1425298948",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11435"
    },
    {
      "text": "val tableQuery = ...",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512048_167879955",
      "id": "20170218-161145_208429016",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11436"
    },
    {
      "text": "%md\n## 4.3 Perform Query\n\nNow that we have a dynamic table, we can perform SQL queries against this table as if it was a normal static table.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h2>4.3 Perform Query</h2>\n<p>Now that we have a dynamic table, we can perform SQL queries against this table as if it was a normal static table.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512048_-289301136",
      "id": "20170218-162010_1110788275",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11437"
    },
    {
      "text": "%sql\n",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [
            {
              "name": "window",
              "index": 0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "topic",
              "index": 1,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "window",
              "index": 0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512048_1665406711",
      "id": "20170218-161337_1103351127",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11438"
    },
    {
      "text": "%md\n## 4.4 Stop Query\n\nIn order to clean everything up, we stop the query again.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h2>4.4 Stop Query</h2>\n<p>In order to clean everything up, we stop the query again.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512048_1066967590",
      "id": "20170218-162048_842521010",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11439"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": [],
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512048_-1205040145",
      "id": "20170218-161329_1844676678",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11440"
    },
    {
      "text": "%md\n# 5. SQL Output\n\nA more meaningful example will store the results in a MySQL database. This allows us better experiments with different output modes and does not require the `Thread.sleep` hack. In order to be able to access the MySQL driver, we need to add the following dependency manually to Zeppelin:\n\n    mysql:mysql-connector-java:6.0.6 \n\nThen we are ready to implement a special `ForeachSink` which allows to output streaming results to arbitrary sinks.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h1>5. SQL Output</h1>\n<p>A more meaningful example will store the results in a MySQL database. This allows us better experiments with different output modes and does not require the <code>Thread.sleep</code> hack. In order to be able to access the MySQL driver, we need to add the following dependency manually to Zeppelin:</p>\n<pre><code>mysql:mysql-connector-java:6.0.6 \n</code></pre>\n<p>Then we are ready to implement a special <code>ForeachSink</code> which allows to output streaming results to arbitrary sinks.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512048_-153335742",
      "id": "20170218-162247_324928954",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11441"
    },
    {
      "text": "%md\n## 5.1 Create JDBCSink\n\nBy extending the class `ForeachWriter` we implement a JDBC sink which writes into a MySQL database. We use UPSERTs in order to be able to process updated data, when we set the output mode to `update`.\n",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": {},
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h2>5.1 Create JDBCSink</h2>\n<p>By extending the class <code>ForeachWriter</code> we implement a JDBC sink which writes into a MySQL database. We use UPSERTs in order to be able to process updated data, when we set the output mode to <code>update</code>.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512048_-1090057193",
      "id": "20180410-172635_366690621",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11442"
    },
    {
      "text": "class JDBCSink(url: String, user:String, pwd:String) extends org.apache.spark.sql.ForeachWriter[org.apache.spark.sql.Row] {\n    import org.apache.commons.lang.StringEscapeUtils\n\n    val driver = \"com.mysql.cj.jdbc.Driver\"\n\n    @transient var connection:java.sql.Connection = _\n    @transient var statement:java.sql.Statement = _\n\n    def open(partitionId: Long, version: Long):Boolean = {\n        Class.forName(driver)\n        connection = java.sql.DriverManager.getConnection(url, user, pwd)\n        statement = connection.createStatement\n        true\n    }\n\n    def process(value: org.apache.spark.sql.Row): Unit = { \n        try {\n            val ts = value(0).toString\n            val topic = StringEscapeUtils.escapeSql(value.getString(1))\n            val freq = value.getLong(2)            \n            statement.executeUpdate(s\"INSERT INTO twitter_topics(ts, topic, frequency) VALUES ('$ts','$topic',$freq) ON DUPLICATE KEY UPDATE frequency=$freq;\")\n        }\n        catch {\n            case t:Throwable =>\n        }\n    }\n\n    def close(errorOrNull:Throwable):Unit = {\n        connection.close\n        connection = null\n        statement = null\n    }\n}\n",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512049_-1282185089",
      "id": "20180410-172620_868376649",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11443"
    },
    {
      "text": "val url = \"jdbc:mysql://kku.training.dimajix-aws.net/training\"\nval user = \"user\"\nval pwd = \"user\"\n\nval sink = new JDBCSink(url, user, pwd)",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512049_-1430733802",
      "id": "20180702-185719_1126231284",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11444"
    },
    {
      "text": "%md\n## 5.2 Create Target Table\n\nIn order to store the results in MySQL, we need to create an appropriate table in MySQL. We use shell commands for that.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h2>5.2 Create Target Table</h2>\n<p>In order to store the results in MySQL, we need to create an appropriate table in MySQL. We use shell commands for that.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512049_-2060684268",
      "id": "20180410-172713_2074707487",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11445"
    },
    {
      "text": "%sh\nmysql --user=user --password=user -e \"CREATE TABLE IF NOT EXISTS training.twitter_topics (ts TIMESTAMP NOT NULL DEFAULT 0, topic VARCHAR(128) NOT NULL, frequency INT NULL, PRIMARY KEY (ts, topic))\"\n",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/sh",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512049_-37684050",
      "id": "20180410-172719_2109390609",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11446"
    },
    {
      "text": "%md\n## 5.3 Perform Aggregation\n\nNow we generate the streaming aggregation again as usual.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<h2>5.3 Perform Aggregation</h2>\n<p>Now we generate the streaming aggregation again as usual.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512049_-642456161",
      "id": "20180410-172735_1591116804",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11447"
    },
    {
      "text": "val windowedCounts = topics\n    .withWatermark(\"ts\", \"90 seconds\")\n    .groupBy(window($\"ts\", \"30 seconds\"), $\"topic\")\n    .agg(sum(lit(1)).as(\"count\"))\n    .coalesce(10)\n    .select(col(\"window.end\"), col(\"topic\"), col(\"count\"))\n",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512049_-1401605180",
      "id": "20180410-172753_1072874526",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11448"
    },
    {
      "text": "%md\n## 5.4 Execute Streaming Query\n\nFinally we start the query. We use the `update` output mode in order to have a low latency of partial results. Triggers should happen every 5 seconds.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>5.4 Execute Streaming Query</h2>\n<p>Finally we start the query. We use the <code>update</code> output mode in order to have a low latency of partial results. Triggers should happen every 5 seconds.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512049_1875549789",
      "id": "20180410-172807_801344669",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11449"
    },
    {
      "text": "import org.apache.spark.sql.streaming.ProcessingTime\n\nval query = windowedCounts.writeStream\n    .foreach(sink)\n    .outputMode(\"update\")\n    .trigger(ProcessingTime(\"5 seconds\"))\n    .queryName(\"topic_counts\")\n    .option(\"checkpointLocation\", \"/tmp/zeppelin/checkpoint-twitter-\" + System.currentTimeMillis())\n    .start()\n",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512049_-518721910",
      "id": "20180410-172813_1777810412",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11450"
    },
    {
      "text": "%md\n## 5.5 Inspect MySQL\n\nNow go to Hue, and see MySQL filling up with data.",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>5.5 Inspect MySQL</h2>\n<p>Now go to Hue, and see MySQL filling up with data.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512049_513399371",
      "id": "20180702-185947_1843596521",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11451"
    },
    {
      "text": "%md\n## 5.6 Stop Query",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": {},
        "enabled": true,
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>5.6 Stop Query</h2>\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512049_813423206",
      "id": "20180702-190012_2092489382",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11452"
    },
    {
      "text": "query.stop()",
      "user": "anonymous",
      "dateUpdated": "2021-09-18T06:45:12+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1631947512049_109703646",
      "id": "20180410-172856_768685341",
      "dateCreated": "2021-09-18T06:45:12+0000",
      "status": "READY",
      "$$hashKey": "object:11453"
    }
  ],
  "name": "Twitter Structured Streaming - Exercise",
  "id": "2GGPBYNKU",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0-preview1",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/Twitter Structured Streaming - Exercise"
}