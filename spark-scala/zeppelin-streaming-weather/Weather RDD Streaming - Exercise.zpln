{"paragraphs":[{"text":"%md\n# Load Station Data\n\nNow we load the station meta data using traditional SparkSQL DataFrame methods. Since the meta data is stored as a simple CSV, this should be simple. Nevertheless we explicitly specify the schema, so we do not need to rely on schema and type inference from Spark. If we did, we might get surprising results, because data is not always as clean as we hope it to be.","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000439_634429082","id":"20170109-002723_896381522","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Load Station Data</h1>\n<p>Now we load the station meta data using traditional SparkSQL DataFrame methods. Since the meta data is stored as a simple CSV, this should be simple. Nevertheless we explicitly specify the schema, so we do not need to rely on schema and type inference from Spark. If we did, we might get surprising results, because data is not always as clean as we hope it to be.</p>\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3637"},{"text":"import org.apache.spark.sql.types.StructType\nimport org.apache.spark.sql.types.StructField\nimport org.apache.spark.sql.types.StringType\nimport org.apache.spark.sql.types.FloatType\nimport org.apache.spark.sql.types.DateType\n\ndef extractFloat = udf((v:String) => if (v != null) v.toFloat else None, FloatType)\n\nval isdSchema = StructType(\n        StructField(\"usaf\", StringType) ::\n        StructField(\"wban\", StringType) ::\n        StructField(\"name\", StringType) ::\n        StructField(\"country\", StringType) ::\n        StructField(\"state\", StringType) ::\n        StructField(\"icao\", StringType) ::\n        StructField(\"latitude\", StringType) ::\n        StructField(\"longitude\", StringType) ::\n        StructField(\"elevation\", StringType) ::\n        StructField(\"date_begin\", DateType) ::\n        StructField(\"date_end\", DateType) ::\n        Nil\n    )\nval isd = sqlContext.read\n    .option(\"header\",\"true\")\n    .option(\"dateFormat\",\"yyyyMMdd\")\n    .schema(isdSchema)\n    .csv(\"s3://dimajix-training/data/weather/isd-history\")\n    .withColumn(\"latitude\", extractFloat($\"latitude\"))\n    .withColumn(\"longitude\", extractFloat($\"longitude\"))\n    .withColumn(\"elevation\", extractFloat($\"elevation\"))\n    \n\nz.show(isd.limit(10))","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"usaf","index":0,"aggr":"sum"}],"values":[{"name":"wban","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"usaf","index":0,"aggr":"sum"},"yAxis":{"name":"wban","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000439_634429082","id":"20170109-002821_386723165","result":{"code":"SUCCESS","type":"TABLE","msg":"usaf\twban\tname\tcountry\tstate\ticao\tlatitude\tlongitude\televation\tdate_begin\tdate_end\n007005\t99999\tCWOS 07005\tnull\tnull\tnull\tnull\tnull\tnull\t2012-01-27\t2012-01-27\n007011\t99999\tCWOS 07011\tnull\tnull\tnull\tnull\tnull\tnull\t2011-10-25\t2012-11-29\n007018\t99999\tWXPOD 7018\tnull\tnull\tnull\t0.0\t0.0\t7018.0\t2011-03-09\t2013-07-30\n007025\t99999\tCWOS 07025\tnull\tnull\tnull\tnull\tnull\tnull\t2012-01-27\t2012-01-27\n007026\t99999\tWXPOD 7026\tAF\tnull\tnull\t0.0\t0.0\t7026.0\t2012-07-13\t2014-11-20\n007034\t99999\tCWOS 07034\tnull\tnull\tnull\tnull\tnull\tnull\t2012-10-24\t2012-11-06\n007037\t99999\tCWOS 07037\tnull\tnull\tnull\tnull\tnull\tnull\t2011-12-02\t2012-11-25\n007044\t99999\tCWOS 07044\tnull\tnull\tnull\tnull\tnull\tnull\t2012-01-27\t2012-01-27\n007047\t99999\tCWOS 07047\tnull\tnull\tnull\tnull\tnull\tnull\t2012-06-13\t2012-07-17\n007052\t99999\tCWOS 07052\tnull\tnull\tnull\tnull\tnull\tnull\t2012-11-29\t2012-11-30\n","comment":"","msgTable":[[{"key":"wban","value":"007005"},{"key":"wban","value":"99999"},{"key":"wban","value":"CWOS 07005"},{"key":"wban","value":"null"},{"key":"wban","value":"null"},{"key":"wban","value":"null"},{"key":"wban","value":"null"},{"key":"wban","value":"null"},{"key":"wban","value":"null"},{"key":"wban","value":"2012-01-27"},{"key":"wban","value":"2012-01-27"}],[{"key":"name","value":"007011"},{"key":"name","value":"99999"},{"key":"name","value":"CWOS 07011"},{"key":"name","value":"null"},{"key":"name","value":"null"},{"key":"name","value":"null"},{"key":"name","value":"null"},{"key":"name","value":"null"},{"key":"name","value":"null"},{"key":"name","value":"2011-10-25"},{"key":"name","value":"2012-11-29"}],[{"key":"country","value":"007018"},{"key":"country","value":"99999"},{"key":"country","value":"WXPOD 7018"},{"key":"country","value":"null"},{"key":"country","value":"null"},{"key":"country","value":"null"},{"key":"country","value":"0.0"},{"key":"country","value":"0.0"},{"key":"country","value":"7018.0"},{"key":"country","value":"2011-03-09"},{"key":"country","value":"2013-07-30"}],[{"key":"state","value":"007025"},{"key":"state","value":"99999"},{"key":"state","value":"CWOS 07025"},{"key":"state","value":"null"},{"key":"state","value":"null"},{"key":"state","value":"null"},{"key":"state","value":"null"},{"key":"state","value":"null"},{"key":"state","value":"null"},{"key":"state","value":"2012-01-27"},{"key":"state","value":"2012-01-27"}],[{"key":"icao","value":"007026"},{"key":"icao","value":"99999"},{"key":"icao","value":"WXPOD 7026"},{"key":"icao","value":"AF"},{"key":"icao","value":"null"},{"key":"icao","value":"null"},{"key":"icao","value":"0.0"},{"key":"icao","value":"0.0"},{"key":"icao","value":"7026.0"},{"key":"icao","value":"2012-07-13"},{"key":"icao","value":"2014-11-20"}],[{"key":"latitude","value":"007034"},{"key":"latitude","value":"99999"},{"key":"latitude","value":"CWOS 07034"},{"key":"latitude","value":"null"},{"key":"latitude","value":"null"},{"key":"latitude","value":"null"},{"key":"latitude","value":"null"},{"key":"latitude","value":"null"},{"key":"latitude","value":"null"},{"key":"latitude","value":"2012-10-24"},{"key":"latitude","value":"2012-11-06"}],[{"key":"longitude","value":"007037"},{"key":"longitude","value":"99999"},{"key":"longitude","value":"CWOS 07037"},{"key":"longitude","value":"null"},{"key":"longitude","value":"null"},{"key":"longitude","value":"null"},{"key":"longitude","value":"null"},{"key":"longitude","value":"null"},{"key":"longitude","value":"null"},{"key":"longitude","value":"2011-12-02"},{"key":"longitude","value":"2012-11-25"}],[{"key":"elevation","value":"007044"},{"key":"elevation","value":"99999"},{"key":"elevation","value":"CWOS 07044"},{"key":"elevation","value":"null"},{"key":"elevation","value":"null"},{"key":"elevation","value":"null"},{"key":"elevation","value":"null"},{"key":"elevation","value":"null"},{"key":"elevation","value":"null"},{"key":"elevation","value":"2012-01-27"},{"key":"elevation","value":"2012-01-27"}],[{"key":"date_begin","value":"007047"},{"key":"date_begin","value":"99999"},{"key":"date_begin","value":"CWOS 07047"},{"key":"date_begin","value":"null"},{"key":"date_begin","value":"null"},{"key":"date_begin","value":"null"},{"key":"date_begin","value":"null"},{"key":"date_begin","value":"null"},{"key":"date_begin","value":"null"},{"key":"date_begin","value":"2012-06-13"},{"key":"date_begin","value":"2012-07-17"}],[{"key":"date_end","value":"007052"},{"key":"date_end","value":"99999"},{"key":"date_end","value":"CWOS 07052"},{"key":"date_end","value":"null"},{"key":"date_end","value":"null"},{"key":"date_end","value":"null"},{"key":"date_end","value":"null"},{"key":"date_end","value":"null"},{"key":"date_end","value":"null"},{"key":"date_end","value":"2012-11-29"},{"key":"date_end","value":"2012-11-30"}]],"columnNames":[{"name":"usaf","index":0,"aggr":"sum"},{"name":"wban","index":1,"aggr":"sum"},{"name":"name","index":2,"aggr":"sum"},{"name":"country","index":3,"aggr":"sum"},{"name":"state","index":4,"aggr":"sum"},{"name":"icao","index":5,"aggr":"sum"},{"name":"latitude","index":6,"aggr":"sum"},{"name":"longitude","index":7,"aggr":"sum"},{"name":"elevation","index":8,"aggr":"sum"},{"name":"date_begin","index":9,"aggr":"sum"},{"name":"date_end","index":10,"aggr":"sum"}],"rows":[["007005","99999","CWOS 07005","null","null","null","null","null","null","2012-01-27","2012-01-27"],["007011","99999","CWOS 07011","null","null","null","null","null","null","2011-10-25","2012-11-29"],["007018","99999","WXPOD 7018","null","null","null","0.0","0.0","7018.0","2011-03-09","2013-07-30"],["007025","99999","CWOS 07025","null","null","null","null","null","null","2012-01-27","2012-01-27"],["007026","99999","WXPOD 7026","AF","null","null","0.0","0.0","7026.0","2012-07-13","2014-11-20"],["007034","99999","CWOS 07034","null","null","null","null","null","null","2012-10-24","2012-11-06"],["007037","99999","CWOS 07037","null","null","null","null","null","null","2011-12-02","2012-11-25"],["007044","99999","CWOS 07044","null","null","null","null","null","null","2012-01-27","2012-01-27"],["007047","99999","CWOS 07047","null","null","null","null","null","null","2012-06-13","2012-07-17"],["007052","99999","CWOS 07052","null","null","null","null","null","null","2012-11-29","2012-11-30"]]},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3638"},{"text":"isd.printSchema()","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000439_634429082","id":"20170109-003002_1177603813","result":{"code":"SUCCESS","type":"TEXT","msg":"root\n |-- usaf: string (nullable = true)\n |-- wban: string (nullable = true)\n |-- name: string (nullable = true)\n |-- country: string (nullable = true)\n |-- state: string (nullable = true)\n |-- icao: string (nullable = true)\n |-- latitude: float (nullable = true)\n |-- longitude: float (nullable = true)\n |-- elevation: float (nullable = true)\n |-- date_begin: date (nullable = true)\n |-- date_end: date (nullable = true)\n\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3639"},{"text":"%md\n## 1. Create a Streaming Context\n\nStreaming is performed using a special StreamingContext, which can be constructed from an existing SparkContext. Additionally a window size for micro batches is required. We want to create a StreamingContext `ssc` from the existing SparkContext `sc` with a micro batch size worth one second.\n","dateUpdated":"2017-02-18T14:43:20+0000","config":{"tableHide":false,"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000439_634429082","id":"20170109-002559_1248270322","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>1. Create a Streaming Context</h2>\n<p>Streaming is performed using a special StreamingContext, which can be constructed from an existing SparkContext. Additionally a window size for micro batches is required. We want to create a StreamingContext <code>ssc</code> from the existing SparkContext <code>sc</code> with a micro batch size worth one second.</p>\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3640"},{"text":"import org.apache.spark.streaming.StreamingContext\nimport org.apache.spark.streaming.Seconds\n\nval ssc = ... // YOUR CODE HERE","dateUpdated":"2017-02-18T14:44:24+0000","config":{"colWidth":12,"editorHide":false,"tableHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000439_634429082","id":"20170109-002712_346811562","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.streaming.StreamingContext\n\nimport org.apache.spark.streaming.Seconds\n\nssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@5ccf49fa\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3641"},{"text":"%md\n## 2. Connect to Data Source\n\nAgain we connect to a simple socket as the datasource. The socket will stream weather data samples in raw format, i.e. one record per line.\n\nIn order to create the sending stream, you can use the `pynetcat` program as follows\n\n    cat /tmp/weather_sample.txt | ./pynetcat.py -I1 -B5 \n    \n**Attention** You need to insert the correct IP address of your clusters master machine here!","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000439_634429082","id":"20170109-020144_1560104238","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>2. Connect to Data Source</h2>\n<p>Again we connect to a simple socket as the datasource. The socket will stream weather data samples in raw format, i.e. one record per line.</p>\n<p>In order to create the sending stream, you can use the <code>pynetcat</code> program as follows</p>\n<pre><code>cat /tmp/weather_sample.txt | ./pynetcat.py -I1 -B5 \n</code></pre>\n<p><strong>Attention</strong> You need to insert the correct IP address of your clusters master machine here!</p>\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3642"},{"text":"import org.apache.spark.storage.StorageLevel\n\n// Put in correct IP address of master within AWS VPC\nval master = \"your-aws-vpc-ip-address\" // YOUR CODE HERE\n\n// Create stream\nval stream = ... // YOUR CODE HERE","dateUpdated":"2017-02-18T14:44:24+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000439_634429082","id":"20170109-005001_1008352335","dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3643","focus":true},{"text":"%md\n### 2.1 Peek Inside\n\nSo let's see if the connection has worked. To do so, we create a simple processing chain which will simply print the results. We will perform the following steps:\n\n1. Perform a `print` action on the raw data stream\n2. Start the StreamingContext, watch the results\n3. Stop the StreamingContext","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170218-135714_1092962011","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>2.1 Peek Inside</h3>\n<p>So let's see if the connection has worked. To do so, we create a simple processing chain which will simply print the results. We will perform the following steps:</p>\n<ol>\n<li>Perform a <code>print</code> action on the raw data stream</li>\n<li>Start the StreamingContext, watch the results</li>\n<li>Stop the StreamingContext</li>\n</ol>\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3644"},{"text":"// 1. Perform 'print' action on the raw data stream\n// YOUR CODE HERE","dateUpdated":"2017-02-18T14:44:53+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170218-135728_1440914941","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3645"},{"text":"// 2. Start the Spark StreamingContext, watch the results\n// YOUR CODE HERE","dateUpdated":"2017-02-18T14:44:53+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170218-135744_1611968879","dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3646","focus":true},{"text":"// 3. Stop the execution using the 'stop' method. You should pass 'false' as an argument to prevent destruction of the underlying SparkContext\n// YOUR CODE HERE","dateUpdated":"2017-02-18T14:44:53+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170218-140306_1782472464","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3647"},{"text":"%md\n## 3. Extract Weather Data\n\nWe create a case class for representing the relevant weather information. We will fill the information using the `map` method of the Spark DStram.\n\nBut before doing so, we need to recreate a StreamingContext and reconnect to the raw data stream, since the previous StreamingContext has been destroyed via the `stop` method above.\n","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-012712_136743186","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>3. Extract Weather Data</h2>\n<p>We create a case class for representing the relevant weather information. We will fill the information using the <code>map</code> method of the Spark DStram.</p>\n<p>But before doing so, we need to recreate a StreamingContext and reconnect to the raw data stream, since the previous StreamingContext has been destroyed via the <code>stop</code> method above.</p>\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3648"},{"text":"// Create new StreamingContext (since previous one has been stopped and is not useable any more)\nval ssc = ... // YOUR CODE HERE\n\n// Reconnect to Stream\nval stream = ... // YOUR CODE HERE\n","dateUpdated":"2017-02-18T14:45:10+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170218-141145_1433115131","dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3649","focus":true},{"text":"case class WeatherData(\n    date:String,\n    time:String,\n    usaf:String,\n    wban:String,\n    airTemperatureQuality:Int,\n    airTemperature:Float,\n    windSpeedQuality:Int,\n    windSpeed:Float\n)\n\nval weatherData = stream.map { row => \n    val date = row.substring(15,23)\n    val time = row.substring(23,27)\n    val usaf = row.substring(4,10)\n    val wban = row.substring(10,15)\n    val airTemperatureQuality = row.charAt(92).toInt - '0'.toInt\n    val airTemperature = row.substring(87,92).toFloat/10\n    val windSpeedQuality = row.charAt(69) - '0'.toInt\n    val windSpeed = row.substring(65,69).toFloat/10\n\n    WeatherData(date,time,usaf,wban,airTemperatureQuality,airTemperature,windSpeedQuality,windSpeed)\n}\n    ","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-012626_729864789","dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3650","focus":true},{"text":"%md\n## 4. Create a Sliding Window\n\nAgain we want to create a sliding window which contains the last 10 seconds worth of data and moves forward every second.","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-012841_979692617","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>4. Create a Sliding Window</h2>\n<p>Again we want to create a sliding window which contains the last 10 seconds worth of data and moves forward every second.</p>\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3651"},{"text":"val windowedData = ... // YOUR CODE HERE","dateUpdated":"2017-02-18T14:45:28+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-005445_504096722","dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3652","focus":true},{"text":"%md\n## 5. Performed grouping and Aggregation\n\nWe now perform the grouping and aggregation, such that we calculate for every 10 second window the following metrics per year and country:\n* Minimum air temperature\n* Maximum air temperature\n* Minimum wind speed\n* Maximum wind speed\n\nAgain we need to evaulate the \"quality\" fields of the incoming data to decide if the correspong wind speed or air temeprature is valid.\n\nIn order to use a higher level API than the RDD API, we simply convcert the Weather RDD to a Dataset using the `toDS` method. Then we can use any DataFrame and/or Dataset method for joining, grouping and aggregation.\n\nWe will both print the final results using the `print` DStream action and also register them as a temporary table using the `createOrReplaceTempView` method of the Dataset.","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-012854_2052710484","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>5. Performed grouping and Aggregation</h2>\n<p>We now perform the grouping and aggregation, such that we calculate for every 10 second window the following metrics per year and country:</p>\n<ul>\n<li>Minimum air temperature</li>\n<li>Maximum air temperature</li>\n<li>Minimum wind speed</li>\n<li>Maximum wind speed</li>\n</ul>\n<p>Again we need to evaulate the &ldquo;quality&rdquo; fields of the incoming data to decide if the correspong wind speed or air temeprature is valid.</p>\n<p>In order to use a higher level API than the RDD API, we simply convcert the Weather RDD to a Dataset using the <code>toDS</code> method. Then we can use any DataFrame and/or Dataset method for joining, grouping and aggregation.</p>\n<p>We will both print the final results using the <code>print</code> DStream action and also register them as a temporary table using the <code>createOrReplaceTempView</code> method of the Dataset.</p>\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3653"},{"text":"// Create a broadcast variable from the stations table, makes sense for streaming\nval stations = broadcast(isd)\n\nwindowedData\n    .transform(rdd => {\n        // 1. Convert RDD to a Dataset[WeatherData]\n        val weather = ... // YOUR CODE HERE\n        // Perform calculation\n        val result = ...\n            // 2. Join with isd data, using 'usaf' and 'wban' columns\n\n            // 3. Extract year from date column (first four letters), store it in 'year'\n\n            // 4. Group by country (from isd) and year (from above)\n\n            // 5. Perform aggregations of min/max of temperature and wind speed\n\n        // 6. Store resulting Dataset as a temporary view using 'createOrReplaceTempView' method\n\n        // 7. Return RDD of Dataset in order to conform with the DStream API\n\n    })\n    // Print first 10 results\n    .print(10)","dateUpdated":"2017-02-18T14:46:26+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-005554_729378682","result":{"code":"SUCCESS","type":"TEXT","msg":"\nstations: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [usaf: string, wban: string ... 9 more fields]\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3654"},{"text":"%md\n# Start!","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-012917_291516717","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Start!</h1>\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3655"},{"text":"ssc.start()","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-005655_1237628677","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3656"},{"text":"%md\n## Peek inside using SQL\n\nSince we registered the result as a SparkSQL temporary table, we can peek inside.","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-021054_1143897633","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Peek inside using SQL</h2>\n<p>Since we registered the result as a SparkSQL temporary table, we can peek inside.</p>\n"},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3657"},{"text":"%sql\nselect * from weather_agg","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"country","index":0,"aggr":"sum"}],"values":[{"name":"year","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"country","index":0,"aggr":"sum"},"yAxis":{"name":"year","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-021019_1195681982","result":{"code":"SUCCESS","type":"TABLE","msg":"country\tyear\ttemp_min\ttemp_max\twind_min\twind_max\nUK\t2004\t4.7\t7.5\t1.5\t3.6\nJA\t2004\t9.7\t9.7\t7.7\t7.7\nPL\t2004\t0.0\t0.0\t3.1\t3.1\nGK\t2004\t9.0\t11.0\t7.2\t13.9\nBE\t2004\t5.5\t10.0\t4.0\t10.3\nUS\t2004\t-26.0\t8.0\t0.0\t7.7\nNO\t2004\t-13.2\t8.0\t0.5\t13.0\nFI\t2004\t-11.0\t-11.0\t3.6\t3.6\nLU\t2004\t9.0\t9.0\t7.2\t7.2\nAU\t2004\t1.0\t2.0\t1.0\t1.0\nNL\t2004\t5.6\t11.7\t4.6\t8.0\nCA\t2004\t8.0\t8.0\t6.2\t6.2\nFR\t2004\t12.0\t12.0\t3.1\t3.1\n","comment":"","msgTable":[[{"key":"year","value":"UK"},{"key":"year","value":"2004"},{"key":"year","value":"4.7"},{"key":"year","value":"7.5"},{"key":"year","value":"1.5"},{"key":"year","value":"3.6"}],[{"key":"temp_min","value":"JA"},{"key":"temp_min","value":"2004"},{"key":"temp_min","value":"9.7"},{"key":"temp_min","value":"9.7"},{"key":"temp_min","value":"7.7"},{"key":"temp_min","value":"7.7"}],[{"key":"temp_max","value":"PL"},{"key":"temp_max","value":"2004"},{"key":"temp_max","value":"0.0"},{"key":"temp_max","value":"0.0"},{"key":"temp_max","value":"3.1"},{"key":"temp_max","value":"3.1"}],[{"key":"wind_min","value":"GK"},{"key":"wind_min","value":"2004"},{"key":"wind_min","value":"9.0"},{"key":"wind_min","value":"11.0"},{"key":"wind_min","value":"7.2"},{"key":"wind_min","value":"13.9"}],[{"key":"wind_max","value":"BE"},{"key":"wind_max","value":"2004"},{"key":"wind_max","value":"5.5"},{"key":"wind_max","value":"10.0"},{"key":"wind_max","value":"4.0"},{"key":"wind_max","value":"10.3"}],[{"value":"US"},{"value":"2004"},{"value":"-26.0"},{"value":"8.0"},{"value":"0.0"},{"value":"7.7"}],[{"value":"NO"},{"value":"2004"},{"value":"-13.2"},{"value":"8.0"},{"value":"0.5"},{"value":"13.0"}],[{"value":"FI"},{"value":"2004"},{"value":"-11.0"},{"value":"-11.0"},{"value":"3.6"},{"value":"3.6"}],[{"value":"LU"},{"value":"2004"},{"value":"9.0"},{"value":"9.0"},{"value":"7.2"},{"value":"7.2"}],[{"value":"AU"},{"value":"2004"},{"value":"1.0"},{"value":"2.0"},{"value":"1.0"},{"value":"1.0"}],[{"value":"NL"},{"value":"2004"},{"value":"5.6"},{"value":"11.7"},{"value":"4.6"},{"value":"8.0"}],[{"value":"CA"},{"value":"2004"},{"value":"8.0"},{"value":"8.0"},{"value":"6.2"},{"value":"6.2"}],[{"value":"FR"},{"value":"2004"},{"value":"12.0"},{"value":"12.0"},{"value":"3.1"},{"value":"3.1"}]],"columnNames":[{"name":"country","index":0,"aggr":"sum"},{"name":"year","index":1,"aggr":"sum"},{"name":"temp_min","index":2,"aggr":"sum"},{"name":"temp_max","index":3,"aggr":"sum"},{"name":"wind_min","index":4,"aggr":"sum"},{"name":"wind_max","index":5,"aggr":"sum"}],"rows":[["UK","2004","4.7","7.5","1.5","3.6"],["JA","2004","9.7","9.7","7.7","7.7"],["PL","2004","0.0","0.0","3.1","3.1"],["GK","2004","9.0","11.0","7.2","13.9"],["BE","2004","5.5","10.0","4.0","10.3"],["US","2004","-26.0","8.0","0.0","7.7"],["NO","2004","-13.2","8.0","0.5","13.0"],["FI","2004","-11.0","-11.0","3.6","3.6"],["LU","2004","9.0","9.0","7.2","7.2"],["AU","2004","1.0","2.0","1.0","1.0"],["NL","2004","5.6","11.7","4.6","8.0"],["CA","2004","8.0","8.0","6.2","6.2"],["FR","2004","12.0","12.0","3.1","3.1"]]},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3658"},{"text":"ssc.stop(false)","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-010018_778177279","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3659"},{"text":"","dateUpdated":"2017-02-18T14:43:20+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487429000440_632505338","id":"20170109-010155_1017767255","dateCreated":"2017-02-18T14:43:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3660"}],"name":"Weather RDD Streaming - Exercise","id":"2CB915DHN","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}