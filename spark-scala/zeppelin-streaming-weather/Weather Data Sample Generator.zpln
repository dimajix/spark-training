{"paragraphs":[{"text":"%md\n# Generating a Sample of Weather Data\nThis notebook will create a sample of weather data to be used for stream processing. We require the sample to contain all years and stations, and the samples should be ordered by timestamp.\n\nBecause our streaming application expects the raw data, we simply access the original raw files.","dateUpdated":"2017-02-18T13:38:22+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487425102724_505788918","id":"20160618-111644_1635493301","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Generating a Sample of Weather Data</h1>\n<p>This notebook will create a sample of weather data to be used for stream processing. We require the sample to contain all years and stations, and the samples should be ordered by timestamp.</p>\n<p>Because our streaming application expects the raw data, we simply access the original raw files.</p>\n"},"dateCreated":"2017-02-18T13:38:22+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:333"},{"text":"val storageLocation = \"s3://dimajix-training/data/weather\"","dateUpdated":"2017-02-18T13:38:39+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487425102724_505788918","id":"20160618-111748_1432174106","dateCreated":"2017-02-18T13:38:22+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:334","dateFinished":"2017-02-18T13:38:39+0000","dateStarted":"2017-02-18T13:38:39+0000","focus":true},{"text":"// Get RDDs for all years\nval raw_weather_years = (2003 to 2014) map {i => sc.textFile(storageLocation + \"/\" + i.toString)}\n\n// Put all RDDs into a single one using the \"union\" method of the SparkContext\nval raw_weather = sc.union(raw_weather_years)","dateUpdated":"2017-02-18T13:38:44+0000","config":{"colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487425102724_505788918","id":"20160618-111846_1820606220","dateCreated":"2017-02-18T13:38:22+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:335","dateFinished":"2017-02-18T13:38:45+0000","dateStarted":"2017-02-18T13:38:44+0000","focus":true},{"text":"raw_weather.take(5).foreach(println)","dateUpdated":"2017-02-18T13:38:49+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487425102724_505788918","id":"20160618-111938_294721450","dateCreated":"2017-02-18T13:38:22+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:336","dateFinished":"2017-02-18T13:38:51+0000","dateStarted":"2017-02-18T13:38:49+0000","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487425186090_2049925817","id":"20170218-133946_339393899","dateCreated":"2017-02-18T13:39:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:847","text":"%md\n## Create and Store Sample\nNow that we have all raw data, we create a sample of 1% of all data entries. We sort the data by timestamp, as this is what we'd (ideally) expect how data is delivered within a streaming context. We store the result into HDFS, and then download it back to the local file system in the next step.","dateUpdated":"2017-02-18T13:41:03+0000","dateFinished":"2017-02-18T13:41:00+0000","dateStarted":"2017-02-18T13:41:00+0000","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Create and Store Sample</h2>\n<p>Now that we have all raw data, we create a sample of 1% of all data entries. We sort the data by timestamp, as this is what we'd (ideally) expect how data is delivered within a streaming context. We store the result into HDFS, and then download it back to the local file system in the next step.</p>\n"}},{"text":"val sample = raw_weather.sample(false, 0.01)\nval sorted = sample.sortBy(_.substring(15,27)).coalesce(10)\nsorted.saveAsTextFile(\"/user/zeppelin/output/weather_sample\")","dateUpdated":"2017-02-18T13:39:07+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487425102724_505788918","id":"20160618-111951_2046894375","dateCreated":"2017-02-18T13:38:22+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:337","dateFinished":"2017-02-18T13:43:31+0000","dateStarted":"2017-02-18T13:39:07+0000","focus":true},{"text":"%sh\nhdfs dfs -getmerge /user/zeppelin/output/weather_sample /tmp/weather_sample.txt\nhead -n10 /tmp/weather_sample.txt","dateUpdated":"2017-02-18T13:43:35+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487425102724_505788918","id":"20160618-112715_1007313092","dateCreated":"2017-02-18T13:38:22+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:338","dateFinished":"2017-02-18T13:43:38+0000","dateStarted":"2017-02-18T13:43:35+0000","focus":true},{"text":"","dateUpdated":"2017-02-18T13:38:22+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487425102725_505404169","id":"20170105-022907_937071531","dateCreated":"2017-02-18T13:38:22+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:339"}],"name":"Weather Data Sample Generator","id":"2CBRF66U2","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}